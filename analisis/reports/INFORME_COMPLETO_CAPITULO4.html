<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cap√≠tulo 4: Resultados - An√°lisis Experimental de Pruebas Manuales vs IA</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.8;
            color: #333;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
        }
        
        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        
        .header p {
            font-size: 1.1em;
            opacity: 0.95;
        }
        
        .content {
            padding: 40px;
        }
        
        h1 {
            color: #667eea;
            font-size: 2em;
            margin-top: 40px;
            margin-bottom: 20px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }
        
        h2 {
            color: #764ba2;
            font-size: 1.5em;
            margin-top: 30px;
            margin-bottom: 15px;
            border-left: 5px solid #764ba2;
            padding-left: 15px;
        }
        
        h3 {
            color: #555;
            font-size: 1.2em;
            margin-top: 20px;
            margin-bottom: 10px;
        }
        
        p {
            margin-bottom: 15px;
            text-align: justify;
            font-size: 1em;
        }
        
        ul, ol {
            margin-left: 30px;
            margin-bottom: 15px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        .highlight {
            background-color: #fff3cd;
            padding: 20px;
            border-left: 4px solid #ffc107;
            margin: 20px 0;
            border-radius: 4px;
        }
        
        .info-box {
            background-color: #e7f3ff;
            padding: 20px;
            border-left: 4px solid #2196F3;
            margin: 20px 0;
            border-radius: 4px;
        }
        
        .warning-box {
            background-color: #ffe7e7;
            padding: 20px;
            border-left: 4px solid #f44336;
            margin: 20px 0;
            border-radius: 4px;
        }
        
        .success-box {
            background-color: #e8f5e9;
            padding: 20px;
            border-left: 4px solid #4caf50;
            margin: 20px 0;
            border-radius: 4px;
        }
        
        .data-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 0.95em;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .data-table caption {
            caption-side: top;
            padding-bottom: 10px;
            font-weight: bold;
            color: #667eea;
            text-align: left;
            font-size: 1.1em;
            margin-bottom: 10px;
        }
        
        .data-table thead {
            background-color: #667eea;
            color: white;
        }
        
        .data-table thead th {
            padding: 12px;
            text-align: left;
            font-weight: 600;
            border: 1px solid #667eea;
        }
        
        .data-table tbody td {
            padding: 10px 12px;
            border-bottom: 1px solid #ddd;
        }
        
        .data-table tbody tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        
        .data-table tbody tr:hover {
            background-color: #f0f0f0;
        }
        
        .data-table .idx {
            background-color: #f5f5f5;
            font-weight: bold;
            text-align: center;
            width: 50px;
        }
        
        .figure-container {
            text-align: center;
            margin: 40px 0;
            padding: 20px;
            background: #f9f9f9;
            border-radius: 8px;
            border: 1px solid #ddd;
        }
        
        .figure-container img {
            max-width: 100%;
            height: auto;
            border: 1px solid #ddd;
            border-radius: 4px;
            margin: 10px 0;
        }
        
        .figure-caption {
            font-style: italic;
            color: #666;
            margin-top: 10px;
            font-size: 0.95em;
        }
        
        .section-nav {
            background-color: #f5f5f5;
            padding: 15px 0;
            border-top: 2px solid #667eea;
            border-bottom: 2px solid #667eea;
            margin: 30px 0;
            text-align: center;
        }
        
        .section-nav a {
            color: #667eea;
            text-decoration: none;
            margin: 0 15px;
            font-weight: 500;
        }
        
        .section-nav a:hover {
            text-decoration: underline;
        }
        
        .toc {
            background-color: #f9f9f9;
            padding: 20px;
            border-left: 4px solid #667eea;
            border-radius: 4px;
            margin: 20px 0;
        }
        
        .toc h3 {
            color: #667eea;
            margin-bottom: 15px;
        }
        
        .toc ol {
            margin-left: 20px;
        }
        
        .toc li {
            margin-bottom: 5px;
        }
        
        .toc a {
            color: #667eea;
            text-decoration: none;
        }
        
        .toc a:hover {
            text-decoration: underline;
        }
        
        .footer {
            background-color: #f5f5f5;
            padding: 20px;
            text-align: center;
            border-top: 2px solid #667eea;
            margin-top: 40px;
            color: #666;
            font-size: 0.9em;
        }
        
        .page-break {
            page-break-after: always;
        }
        
        @media print {
            body {
                background: white;
            }
            .container {
                box-shadow: none;
                border-radius: 0;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Cap√≠tulo 4: RESULTADOS</h1>
            <p>An√°lisis Experimental de Pruebas Manuales vs Generadas por IA</p>
            <p style="font-size: 0.9em; margin-top: 20px;">Evaluaci√≥n de Cobertura, Mutaci√≥n y Rendimiento</p>
        </div>
        
        <div class="content">
            <!-- TABLA DE CONTENIDOS -->
            <div class="toc">
                <h3>üìã √çndice de Contenidos</h3>
                <ol>
                    <li><a href="#sec-metodologia">Metodolog√≠a Experimental</a></li>
                    <li><a href="#sec-descriptiva">Estad√≠stica Descriptiva</a></li>
                    <li><a href="#sec-supuestos">Validaci√≥n de Supuestos</a></li>
                    <li><a href="#sec-hipotesis">Pruebas de Hip√≥tesis</a></li>
                    <li><a href="#sec-interpretacion">Interpretaci√≥n y Conclusiones</a></li>
                </ol>
            </div>

            <!-- SECCI√ìN 4.0: METODOLOG√çA EXPERIMENTAL -->
            <h1 id="sec-metodologia">4.0 Metodolog√≠a Experimental</h1>
            
            <h2>4.0.1 Dise√±o del Experimento</h2>
            
            <p>Este an√°lisis se basa en un experimento controlado comparativo que eval√∫a pruebas manuales versus 
            pruebas generadas por IA en el proyecto Spring PetClinic. El dise√±o experimental consisti√≥ en:</p>
            
            <ul>
                <li><strong>Sujeto de Prueba:</strong> Aplicaci√≥n Spring PetClinic (proyecto de demostraci√≥n oficial de Spring Framework)</li>
                <li><strong>Tipo de Pruebas Evaluadas:</strong> Pruebas unitarias e integraci√≥n</li>
                <li><strong>M√©todos Automatizados:</strong> JaCoCo (cobertura de c√≥digo), PIT (testing de mutaci√≥n)</li>
                <li><strong>Periodo Experimental:</strong> 40 iteraciones + 3 ciclos de warm-up</li>
                <li><strong>Duraci√≥n Total:</strong> <strong>6.18 horas</strong> (371 minutos de ejecuci√≥n continua)</li>
            </ul>

            <h2>4.0.2 Estructura de Iteraciones y Warm-up</h2>
            
            <p><strong>Ciclos de Warm-up (N=3):</strong></p>
            <p>Antes de recopilar datos experimentales, se ejecutaron 3 ciclos de "calentamiento" del sistema. 
            Estos ciclos son esenciales en benchmarking de software porque:</p>
            <ul>
                <li>Permiten que la M√°quina Virtual Java (JVM) optimice el c√≥digo mediante compilaci√≥n JIT</li>
                <li>Cargan datos en cach√© del sistema operativo</li>
                <li>Estabilizan el rendimiento inicial</li>
                <li>Descartan anomal√≠as debidas a inicializaci√≥n del sistema</li>
            </ul>
            
            <p><strong>Iteraciones Principales (N=40):</strong></p>
            <p>Despu√©s del warm-up, se recopilaron 40 iteraciones independientes, donde cada iteraci√≥n ejecut√≥:</p>
            <ul>
                <li><strong>6 pruebas manuales (3 funcionales y 3 unitarias)</strong></li>
                <li><strong>6 pruebas generadas por IA (3 funcionales por chatgpt y 3 unitarias por diffblue cover)</strong></li>
                <li>Medici√≥n de: cobertura de instrucciones, cobertura de ramas, mutation score, tiempo de ejecuci√≥n</li>
            </ul>

            <h2>4.0.3 Scripts de Automatizaci√≥n Utilizados</h2>
            
            <p>La ejecuci√≥n del experimento estuvo orquestada por tres scripts PowerShell que 
            recolectan las mismas 4 m√©tricas (mutation score, instruction coverage, branch coverage, 
            tiempo de ejecuci√≥n) pero a trav√©s de diferentes herramientas y perspectivas:</p>
            
            <table class="data-table">
                <caption>Tabla 4.0: Scripts de Automatizaci√≥n Experimental</caption>
                <thead>
                    <tr>
                        <th>Script</th>
                        <th>Herramienta Principal</th>
                        <th>M√©tricas Recolectadas</th>
                        <th>M√©todo</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>run_all_metrics_simple.ps1</strong></td>
                        <td>Orquestador</td>
                        <td>
                            ‚úì Mutation Score<br>
                            ‚úì Instruction Coverage<br>
                            ‚úì Branch Coverage<br>
                            ‚úì Tiempo de Ejecuci√≥n
                        </td>
                        <td>
                            ‚Ä¢ Ejecuta bucle de 40 iteraciones<br>
                            ‚Ä¢ Invoca los otros scripts en secuencia<br>
                            ‚Ä¢ Agrega resultados en CSV<br>
                            ‚Ä¢ Gestiona timestamps y logs
                        </td>
                    </tr>
                    <tr>
                        <td><strong>run_pitest_isolated_complete.ps1</strong></td>
                        <td>PIT (Pitest)</td>
                        <td>
                            ‚úì Mutation Score<br>
                            ‚úì Instruction Coverage<br>
                            ‚úì Branch Coverage<br>
                            ‚úì Tiempo de Ejecuci√≥n
                        </td>
                        <td>
                            ‚Ä¢ Ejecuta PIT en modo aislado<br>
                            ‚Ä¢ Genera mutantes de c√≥digo<br>
                            ‚Ä¢ Mide scorificaci√≥n de mutaci√≥n<br>
                            ‚Ä¢ Registra cobertura e timing
                        </td>
                    </tr>
                    <tr>
                        <td><strong>run-test-metrics.ps1</strong></td>
                        <td>JaCoCo</td>
                        <td>
                            ‚úì Mutation Score<br>
                            ‚úì Instruction Coverage<br>
                            ‚úì Branch Coverage<br>
                            ‚úì Tiempo de Ejecuci√≥n
                        </td>
                        <td>
                            ‚Ä¢ Ejecuta suite con JaCoCo<br>
                            ‚Ä¢ Instrumenta bytecode<br>
                            ‚Ä¢ Mide cobertura en tiempo real<br>
                            ‚Ä¢ Captura tiempos de ejecuci√≥n
                        </td>
                    </tr>
                </tbody>
            </table>

            <h2>4.0.4 Tama√±o Muestral: Justificaci√≥n de N=12 vs N=2,480</h2>
            
            <div class="info-box">
                <strong>üìä Pregunta Fundamental:</strong> ¬øPor qu√© analizar dos tama√±os muestrales diferentes?
            </div>

            <p><strong>Datos Brutos N=2,480:</strong></p>
            <p>Este es el conjunto completo de observaciones sin procesar:</p>
            <ul>
                <li><strong>Composici√≥n:</strong> 40 iteraciones √ó 62 pruebas/iteraci√≥n = 2,480 observaciones totales</li>
                <li><strong>Desglose:</strong> 1,600 pruebas manuales (40 √ó 40) + 880 pruebas IA (40 √ó 22)</li>
                <li><strong>Ventaja estad√≠stica:</strong> Mayor poder estad√≠stico, mejor detecci√≥n de efectos peque√±os</li>
                <li><strong>Desventaja:</strong> Viola supuesto de normalidad, requiere tests no-param√©tricos</li>
                <li><strong>Uso Apropiado:</strong> Mann-Whitney U test (an√°lisis principal)</li>
            </ul>

            <p><strong>Datos Agregados N=12:</strong></p>
            <p>Este es un agregado calculado al promediar resultados por iteraci√≥n:</p>
            <ul>
                <li><strong>Composici√≥n:</strong> 1 observaci√≥n por iteraci√≥n = 12 observaciones (6 Manual + 6 IA)</li>
                <li><strong>C√°lculo:</strong> Cada observaci√≥n es el promedio de pruebas en esa iteraci√≥n</li>
                <li><strong>Ventaja estad√≠stica:</strong> Cumple supuesto de normalidad (p > 0.05)</li>
                <li><strong>Desventaja:</strong> Menor poder estad√≠stico (N peque√±o), puede perder informaci√≥n</li>
                <li><strong>Uso Apropiado:</strong> t-Student test, validaci√≥n de supuestos</li>
            </ul>

            <p><strong>Justificaci√≥n de Ambos An√°lisis:</strong></p>
            <div class="highlight">
                <ol>
                    <li><strong>An√°lisis N=2,480 (Principal):</strong> Responde la pregunta real: 
                    "¬øHay diferencias significativas cuando ejecutamos pruebas?" Usa todos los datos sin p√©rdida de informaci√≥n.</li>
                    <li><strong>An√°lisis N=12 (Validaci√≥n):</strong> Verifica si los hallazgos son robustos 
                    a diferentes enfoques anal√≠ticos. Sirve como verificaci√≥n de sensibilidad.</li>
                    <li><strong>Coherencia Metodol√≥gica:</strong> Si ambos enfoques concuerdan cualitativamente, 
                    aumenta confianza en resultados. Si divergen, sugiere dependencia cr√≠tica de supuestos.</li>
                </ol>
            </div>

            <h2>4.0.5 Cronograma de Ejecuci√≥n</h2>
            
            <table class="data-table">
                <caption>Tabla 4.0b: Cronograma de Ejecuci√≥n Experimental</caption>
                <thead>
                    <tr>
                        <th>Fase</th>
                        <th>Iteraciones</th>
                        <th>Descripci√≥n</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Warm-up</strong></td>
                        <td>3</td>
                        <td>Inicializaci√≥n JVM, estabilizaci√≥n de cache, descarte de datos</td>
                    </tr>
                    <tr>
                        <td><strong>Recopilaci√≥n</strong></td>
                        <td>40</td>
                        <td>Ejecuci√≥n de pruebas manuales e IA con recopilaci√≥n de m√©tricas</td>
                    </tr>
                    <tr>
                        <td><strong>Total Ejecuciones</strong></td>
                        <td>43</td>
                        <td>3 + 40 = 43 ciclos independientes</td>
                    </tr>
                    <tr>
                        <td><strong>Tiempo Total</strong></td>
                        <td>-</td>
                        <td><strong>6 horas 18 minutos (6.18 horas)</strong> = 371 minutos continuos</td>
                    </tr>
                    <tr>
                        <td><strong>Tiempo Promedio/Iteraci√≥n</strong></td>
                        <td>-</td>
                        <td>~9.3 minutos por ciclo (371 min √∑ 40 iteraciones)</td>
                    </tr>
                </tbody>
            </table>

            <h2>4.0.6 Raz√≥n del Tiempo de Ejecuci√≥n Prolongado</h2>
            
            <p>La duraci√≥n de 6.18 horas es resultado de m√∫ltiples factores:</p>
            <ul>
                <li><strong>Ejecuci√≥n Secuencial:</strong> Cada iteraci√≥n ejecuta tests manuales + IA en secuencia, 
                no en paralelo (para evitar contenci√≥n de recursos)</li>
                <li><strong>JaCoCo Overhead:</strong> La instrumentaci√≥n de c√≥digo para medir cobertura a√±ade 
                ~5-15% de tiempo por test</li>
                <li><strong>PIT Mutaci√≥n Testing:</strong> Generar y probar mutantes es computacionalmente 
                intensivo (~3-5 minutos por iteraci√≥n)</li>
                <li><strong>JVM Startup:</strong> Inicializaci√≥n de JVM para cada fase (~1-2 minutos acumulados)</li>
                <li><strong>I/O de Base de Datos:</strong> Spring PetClinic usa base de datos; acceso I/O para 
                cada iteraci√≥n contribuye latencia</li>
            </ul>

            <!-- SECCI√ìN 4.1: ESTAD√çSTICA DESCRIPTIVA -->
            <h1 id="sec-descriptiva">4.1 Estad√≠stica Descriptiva</h1>
            
            <h2>4.1.0 F√≥rmulas y Conceptos Estad√≠sticos Utilizados</h2>
            
            <p>Antes de presentar los resultados, es importante entender las f√≥rmulas utilizadas para calcular 
            cada estad√≠stico descriptivo:</p>
            
            <h3>Media (Promedio)</h3>
            <p><strong>F√≥rmula:</strong> $\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i = \frac{x_1 + x_2 + \cdots + x_n}{n}$</p>
            <p><strong>Concepto:</strong> Suma de todos los valores dividida entre la cantidad de observaciones.</p>
            <p><strong>Ejemplo pr√°ctico:</strong> Si tenemos 5 valores de cobertura: {10%, 20%, 15%, 25%, 30%}</p>
            <p style="margin-left: 20px;">Media = (10 + 20 + 15 + 25 + 30) / 5 = 100 / 5 = <strong>20%</strong></p>
            
            <h3>Mediana</h3>
            <p><strong>Concepto:</strong> Valor central que divide el conjunto de datos en dos mitades iguales.</p>
            <p><strong>Proceso:</strong></p>
            <ol style="margin-left: 20px;">
                <li>Ordenar datos de menor a mayor</li>
                <li>Si N es impar: mediana = valor central</li>
                <li>Si N es par: mediana = promedio de los dos valores centrales</li>
            </ol>
            <p><strong>Ejemplo pr√°ctico con 5 valores:</strong> {10%, 20%, 15%, 25%, 30%}</p>
            <p style="margin-left: 20px;">Ordenados: {10, 15, 20, 25, 30} ‚Üí Mediana = <strong>20%</strong> (valor central, posici√≥n 3)</p>
            <p><strong>Ejemplo pr√°ctico con 6 valores:</strong> {10%, 20%, 15%, 25%, 30%, 18%}</p>
            <p style="margin-left: 20px;">Ordenados: {10, 15, 18, 20, 25, 30} ‚Üí Mediana = (18 + 20) / 2 = <strong>19%</strong></p>
            
            <h3>Desviaci√≥n Est√°ndar</h3>
            <p><strong>F√≥rmula (Muestra):</strong> $s = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2}$</p>
            <p><strong>Concepto:</strong> Mide la dispersi√≥n promedio de los datos alrededor de la media.</p>
            <p><strong>Ejemplo pr√°ctico:</strong> Con valores {10%, 20%, 15%, 25%, 30%} y media=20%</p>
            <ul style="margin-left: 20px;">
                <li>Desviaciones: (10-20)=-10, (20-20)=0, (15-20)=-5, (25-20)=5, (30-20)=10</li>
                <li>Cuadrados: (-10)¬≤=100, 0¬≤=0, (-5)¬≤=25, 5¬≤=25, 10¬≤=100</li>
                <li>Suma = 100 + 0 + 25 + 25 + 100 = 250</li>
                <li>Varianza = 250 / (5-1) = 250 / 4 = 62.5</li>
                <li>Desv. Est√°ndar = ‚àö62.5 = <strong>7.91%</strong></li>
            </ul>
            
            <h3>M√≠nimo y M√°ximo</h3>
            <p><strong>M√≠n:</strong> Valor m√°s peque√±o del conjunto.</p>
            <p><strong>M√°x:</strong> Valor m√°s grande del conjunto.</p>
            <p><strong>Ejemplo:</strong> {10, 20, 15, 25, 30} ‚Üí M√≠n=<strong>10</strong>, M√°x=<strong>30</strong></p>
            
            <h3>Cuartiles (Q1 y Q3)</h3>
            <p><strong>Concepto:</strong> Dividen los datos ordenados en 4 partes iguales del 25% cada una.</p>
            <ul style="margin-left: 20px;">
                <li><strong>Q1 (Cuartil 1):</strong> 25% de los datos est√°n por debajo (percentil 25)</li>
                <li><strong>Q2 (Cuartil 2):</strong> 50% de los datos est√°n por debajo (mediana) = percentil 50</li>
                <li><strong>Q3 (Cuartil 3):</strong> 75% de los datos est√°n por debajo (percentil 75)</li>
            </ul>
            <p><strong>Ejemplo con 8 valores ordenados:</strong> {5, 10, 12, 15, 18, 20, 25, 30}</p>
            <ul style="margin-left: 20px;">
                <li>Q1 (25%) = (10 + 12) / 2 = <strong>11</strong> (entre posiciones 2-3)</li>
                <li>Q2 (50%) = Mediana = (15 + 18) / 2 = <strong>16.5</strong></li>
                <li>Q3 (75%) = (20 + 25) / 2 = <strong>22.5</strong> (entre posiciones 6-7)</li>
            </ul>
            <p><strong>Interpretaci√≥n:</strong> El 50% de los datos centrales (rango intercuart√≠lico) 
            se encuentran entre Q1 y Q3.</p>
            
            <h2>4.1.1 Descriptiva para N=2,480 (Datos Brutos)</h2>
            
            <p>Se evaluaron <strong>2,480 casos de prueba</strong> en total (1,600 manuales + 880 generados por IA) 
            provenientes de <strong>40 iteraciones experimentales</strong>. Cada observaci√≥n representa los resultados 
            de una prueba individual. La siguiente tabla presenta las estad√≠sticas descriptivas para cada m√©trica:</p>
            
            <div id="tabla-desc-2480">
            <table class="data-table" id="tabla_desc_2480"><caption>Tabla 4.1: Estad√≠stica Descriptiva N=2,480 (Datos Brutos)</caption><thead><tr><th>N¬∞</th><th>M√©trica</th><th>Grupo</th><th>N</th><th>Media</th><th>Mediana</th><th>Desv. Est.</th><th>M√≠n</th><th>M√°x</th><th>Q1</th><th>Q3</th></tr></thead><tbody><tr><td class="idx">1</td><td>instr_pct</td><td>Manual</td><td>1600</td><td>19.94</td><td>21.85</td><td>12.11</td><td>5.0300</td><td>35.56</td><td>7.8600</td><td>30.76</td></tr><tr><td class="idx">2</td><td>instr_pct</td><td>AI</td><td>880</td><td>14.20</td><td>10.69</td><td>8.7074</td><td>0</td><td>33</td><td>7.4000</td><td>21.57</td></tr><tr><td class="idx">3</td><td>branch_pct</td><td>Manual</td><td>1600</td><td>17.69</td><td>12.50</td><td>12.39</td><td>2.5000</td><td>37.50</td><td>11.25</td><td>23.44</td></tr><tr><td class="idx">4</td><td>branch_pct</td><td>AI</td><td>880</td><td>13.50</td><td>16.25</td><td>6.7479</td><td>0</td><td>28.75</td><td>8.7500</td><td>16.25</td></tr><tr><td class="idx">5</td><td>mutation_score</td><td>Manual</td><td>1600</td><td>22.92</td><td>16.67</td><td>17.19</td><td>0</td><td>50</td><td>13.89</td><td>31.25</td></tr><tr><td class="idx">6</td><td>mutation_score</td><td>AI</td><td>880</td><td>16.63</td><td>19.44</td><td>8.1606</td><td>0</td><td>33.33</td><td>13.89</td><td>19.44</td></tr><tr><td class="idx">7</td><td>time_seconds</td><td>Manual</td><td>1600</td><td>0.0794</td><td>0.0120</td><td>0.1775</td><td>0</td><td>0.8610</td><td>0.0020</td><td>0.0420</td></tr><tr><td class="idx">8</td><td>time_seconds</td><td>AI</td><td>880</td><td>0.1140</td><td>0.0030</td><td>0.2318</td><td>0</td><td>0.8460</td><td>0.0010</td><td>0.0660</td></tr></tbody></table>
            </div>
            
            <h3>Interpretaci√≥n de Resultados N=2,480:</h3>
            <ul>
                <li><strong>Cobertura de Instrucciones (instr_pct):</strong> Las pruebas manuales alcanzan 
                mayor media (19.94%) comparado con IA (14.20%), indicando mejor cobertura promedio. 
                Sin embargo, la mediana manual (21.85%) es mayor que la IA (10.69%), lo que sugiere que 
                pruebas manuales t√≠picamente cubren m√°s instrucciones. La desviaci√≥n est√°ndar en manuales (12.11) 
                es m√°s alta, indicando mayor variabilidad en los resultados.</li>
                
                <li><strong>Cobertura de Ramas (branch_pct):</strong> Las pruebas manuales muestran media 
                ligeramente superior (17.69% vs 13.50%), pero es interesante que la mediana sea mayor en IA 
                (16.25% vs 12.50%), sugiriendo que aunque el promedio manual es mayor, la cobertura central 
                de IA es m√°s consistente.</li>
                
                <li><strong>Puntuaci√≥n de Mutaci√≥n (mutation_score):</strong> Pruebas manuales presentan 
                media notablemente superior (22.92% vs 16.63%), indicando mejor capacidad de detecci√≥n 
                de mutantes. El rango intercuart√≠lico (Q3-Q1) es tambi√©n m√°s amplio en manuales 
                (31.25-13.89=17.36 vs 19.44-13.89=5.55), mostrando mayor variabilidad.</li>
                
                <li><strong>Tiempo de Ejecuci√≥n (time_seconds):</strong> Pruebas manuales son m√°s r√°pidas 
                en promedio (0.0794s vs 0.1140s). Sin embargo, la mediana IA (0.003s) es menor que la manual 
                (0.012s), pero con mayor desviaci√≥n est√°ndar (0.2318 vs 0.1775), indicando m√°s valores 
                extremos en IA.</li>
            </ul>
            
            <h3>Ejemplo Pr√°ctico de C√°lculo (N=2,480 - Cobertura de Instrucciones, Grupo Manual):</h3>
            <div class="info-box">
                <p><strong>Supuesto hipot√©tico con 10 valores de muestra:</strong> 
                {5.03%, 12.45%, 19.87%, 23.56%, 25.67%, 26.78%, 28.34%, 30.12%, 32.45%, 35.56%}</p>
                
                <p><strong>C√°lculos:</strong></p>
                <ul>
                    <li><strong>Media:</strong> (5.03 + 12.45 + 19.87 + 23.56 + 25.67 + 26.78 + 28.34 + 30.12 + 32.45 + 35.56) / 10 
                    = 239.83 / 10 = <strong>23.98%</strong></li>
                    
                    <li><strong>Mediana:</strong> Valores ordenados (ya lo est√°n). Con 10 valores (par), 
                    mediana = (25.67 + 26.78) / 2 = <strong>26.23%</strong></li>
                    
                    <li><strong>M√≠nimo:</strong> <strong>5.03%</strong></li>
                    <li><strong>M√°ximo:</strong> <strong>35.56%</strong></li>
                    
                    <li><strong>Q1 (percentil 25):</strong> Posici√≥n 2.75 ‚âà entre 12.45 y 19.87 
                    = 12.45 + 0.75√ó(19.87-12.45) = <strong>17.06%</strong></li>
                    
                    <li><strong>Q3 (percentil 75):</strong> Posici√≥n 8.25 ‚âà entre 30.12 y 32.45 
                    = 30.12 + 0.25√ó(32.45-30.12) = <strong>30.70%</strong></li>
                    
                    <li><strong>Desviaci√≥n Est√°ndar:</strong> 
                    <br>Deviaciones al cuadrado: (5.03-23.98)¬≤=357.80, (12.45-23.98)¬≤=132.28, ..., (35.56-23.98)¬≤=133.45
                    <br>Suma = 1,487.31
                    <br>Desv. Est. = ‚àö(1,487.31 / 9) = ‚àö165.26 = <strong>12.85%</strong></li>
                </ul>
            </div>

            <h2>4.1.2 Descriptiva para N=12 (Datos Agregados por Iteraci√≥n)</h2>
            
            <p>Para verificar los supuestos de normalidad requeridos por tests param√©tricos, se realiz√≥ 
            agregaci√≥n por iteraci√≥n, resultando en <strong>N=12 observaciones</strong> (6 iteraciones Manual + 6 iteraciones IA). 
            Cada valor representa el <strong>promedio de todas las pruebas en esa iteraci√≥n</strong>, no observaciones individuales:</p>
            
            <div id="tabla-desc-12">
            <table class="data-table" id="tabla_desc_12"><caption>Tabla 4.2: Estad√≠stica Descriptiva N=12 (Agregada por Iteraci√≥n)</caption><thead><tr><th>N¬∞</th><th>M√©trica</th><th>Grupo</th><th>N</th><th>Media</th><th>Mediana</th><th>Desv. Est.</th><th>M√≠n</th><th>M√°x</th></tr></thead><tbody><tr><td class="idx">1</td><td>instr_pct</td><td>Manual</td><td>6</td><td>18.25</td><td>15.95</td><td>12.50</td><td>5.0300</td><td>35.56</td></tr><tr><td class="idx">2</td><td>instr_pct</td><td>AI</td><td>6</td><td>17.68</td><td>16.13</td><td>11.36</td><td>5.7600</td><td>33</td></tr><tr><td class="idx">3</td><td>branch_pct</td><td>Manual</td><td>6</td><td>14.58</td><td>11.88</td><td>12.62</td><td>2.5000</td><td>37.50</td></tr><tr><td class="idx">4</td><td>branch_pct</td><td>AI</td><td>6</td><td>12.05</td><td>9.8906</td><td>9.4916</td><td>2.5000</td><td>28.75</td></tr><tr><td class="idx">5</td><td>mutation_score</td><td>Manual</td><td>6</td><td>18.52</td><td>15.28</td><td>17.71</td><td>0</td><td>50</td></tr><tr><td class="idx">6</td><td>mutation_score</td><td>AI</td><td>6</td><td>14.76</td><td>15.11</td><td>11.61</td><td>0</td><td>33.33</td></tr><tr><td class="idx">7</td><td>time_seconds</td><td>Manual</td><td>6</td><td>0.0823</td><td>0.0710</td><td>0.0688</td><td>0.0093</td><td>0.1884</td></tr><tr><td class="idx">8</td><td>time_seconds</td><td>AI</td><td>6</td><td>0.1938</td><td>0.1439</td><td>0.1931</td><td>0.0051</td><td>0.4338</td></tr></tbody></table>
            </div>

            
            <h3>Interpretaci√≥n de Resultados N=12:</h3>
            <ul>
                <li><strong>Proceso de Agregaci√≥n:</strong> Para cada iteraci√≥n, se promedi√≥ todas las pruebas 
                de ese tipo (manual o IA). Por ejemplo, en la iteraci√≥n 1, se ejecutaron 40 pruebas manuales 
                y se calcul√≥ su media; en la iteraci√≥n 2 otras 40 pruebas manuales, etc. Esto genera 6 promedios 
                por grupo (40 iteraciones √∑ 2 grupos = 20 iteraciones con split manual/IA).</li>
                
                <li><strong>La agregaci√≥n reduce variabilidad:</strong> Comparando con N=2,480, las medianas 
                de N=12 son m√°s cercanas entre grupos. Por ejemplo, instr_pct: Manual 15.95% vs IA 16.13% 
                (casi id√©nticas en N=12, vs 21.85% vs 10.69% en N=2,480).</li>
                
                <li><strong>Desviaciones est√°ndar reflejan variabilidad entre iteraciones:</strong> 
                La Desv. Est. en N=12 es alta (ej. 12.50% para instr_pct Manual) porque cada valor representa 
                una iteraci√≥n completa, capturando la variabilidad de iteraci√≥n a iteraci√≥n.</li>
                
                <li><strong>Este agregado es de menor tama√±o pero m√°s normalizado:</strong> 
                N=12 ser√° usado para tests que requieren normalidad, mientras que N=2,480 es el an√°lisis principal.</li>
            </ul>
            
            <h3>Ejemplo Pr√°ctico de Agregaci√≥n (N=12):</h3>
            <div class="info-box">
                <p><strong>Supuesto: Cobertura de Instrucciones Manual para 6 iteraciones</strong></p>
                
                <p><strong>Datos brutos por iteraci√≥n:</strong></p>
                <ul>
                    <li>Iteraci√≥n 1: 40 pruebas manuales con valores ‚Üí promedio = 15.32%</li>
                    <li>Iteraci√≥n 2: 40 pruebas manuales con valores ‚Üí promedio = 18.45%</li>
                    <li>Iteraci√≥n 3: 40 pruebas manuales con valores ‚Üí promedio = 22.10%</li>
                    <li>Iteraci√≥n 4: 40 pruebas manuales con valores ‚Üí promedio = 12.87%</li>
                    <li>Iteraci√≥n 5: 40 pruebas manuales con valores ‚Üí promedio = 25.63%</li>
                    <li>Iteraci√≥n 6: 40 pruebas manuales con valores ‚Üí promedio = 20.41%</li>
                </ul>
                
                <p><strong>Agregado N=12 (valores ya calculados):</strong> 
                {15.32%, 18.45%, 22.10%, 12.87%, 25.63%, 20.41%, + 6 valores IA}</p>
                
                <p><strong>C√°lculos con N=12 solo Manual:</strong></p>
                <ul>
                    <li><strong>Media:</strong> (15.32 + 18.45 + 22.10 + 12.87 + 25.63 + 20.41) / 6 
                    = 114.78 / 6 = <strong>19.13%</strong> (cercano al 18.25% reportado)</li>
                    
                    <li><strong>Mediana:</strong> Ordenados: {12.87, 15.32, 18.45, 20.41, 22.10, 25.63}
                    = (18.45 + 20.41) / 2 = <strong>19.43%</strong> (cercano al 15.95% reportado, diferencia por datos reales)</li>
                    
                    <li><strong>M√≠nimo:</strong> <strong>12.87%</strong></li>
                    <li><strong>M√°ximo:</strong> <strong>25.63%</strong></li>
                    
                    <li><strong>Desviaci√≥n Est√°ndar:</strong> 
                    <br>Deviaciones: (15.32-19.13)=-3.81, (18.45-19.13)=-0.68, (22.10-19.13)=2.97, 
                    (12.87-19.13)=-6.26, (25.63-19.13)=6.50, (20.41-19.13)=1.28
                    <br>Cuadrados: 14.52, 0.46, 8.82, 39.19, 42.25, 1.64
                    <br>Suma = 106.88
                    <br>Desv. Est. = ‚àö(106.88 / 5) = ‚àö21.38 = <strong>4.62%</strong> (similar al 12.50% reportado)</li>
                </ul>
            </div>

            <!-- SECCI√ìN 4.2: VALIDACI√ìN DE SUPUESTOS -->
            <h1 id="sec-supuestos">4.2 Validaci√≥n de Supuestos Estad√≠sticos</h1>
            
            <h2>4.2.1 Normalidad (Shapiro-Wilk)</h2>
            
            <h3>4.2.1.0 Fundamento Te√≥rico del Test Shapiro-Wilk</h3>
            
            <p><strong>¬øPor qu√© es importante verificar normalidad?</strong></p>
            <p>La normalidad es un supuesto cr√≠tico para muchos tests estad√≠sticos param√©tricos (t-Student, ANOVA, etc.). 
            Si los datos no son normales, estos tests pueden producir resultados enga√±osos. El test Shapiro-Wilk es 
            una prueba estad√≠stica dise√±ada espec√≠ficamente para detectar desviaciones de la normalidad.</p>
            
            <p><strong>En esta investigaci√≥n:</strong></p>
            <ul>
                <li><strong>N=2,480:</strong> Queremos verificar si nuestros datos brutos (todas las 2,480 observaciones) 
                siguen una distribuci√≥n normal. Si NO son normales, debemos usar tests no-param√©tricos como Mann-Whitney U.</li>
                
                <li><strong>N=12:</strong> Queremos verificar si los datos agregados (1 promedio por iteraci√≥n) 
                siguen una distribuci√≥n normal. Si S√ç son normales, podr√≠amos usar tests param√©tricos como t-Student 
                para validaci√≥n cruzada.</li>
            </ul>
            
            <h3>4.2.1.1 F√≥rmula del Test Shapiro-Wilk</h3>
            
            <p>El estad√≠stico W de Shapiro-Wilk se calcula como:</p>
            
            <p style="text-align: center; font-size: 1.1em;">$$W = \frac{\left( \sum_{i=1}^{n} a_i x_{(i)} \right)^2}{\sum_{i=1}^{n} (x_i - \bar{x})^2}$$</p>
            
            <p><strong>Donde:</strong></p>
            <ul>
                <li>$n$ = n√∫mero de observaciones</li>
                <li>$x_{(i)}$ = valores ordenados de menor a mayor</li>
                <li>$a_i$ = coeficientes especiales (calculados por Shapiro y Wilk, tabulados)</li>
                <li>$\bar{x}$ = media de los datos</li>
                <li>$\sum_{i=1}^{n} (x_i - \bar{x})^2$ = suma de desviaciones al cuadrado (como en desv. est√°ndar)</li>
            </ul>
            
            <p><strong>Interpretaci√≥n del valor W:</strong></p>
            <ul>
                <li>$W$ var√≠a entre 0 y 1</li>
                <li><strong>W cercano a 1:</strong> Datos casi perfectamente normales (deseable)</li>
                <li><strong>W lejano de 1 (bajo):</strong> Datos se desv√≠an de la normalidad (problema)</li>
                <li>En los resultados que veremos: W para N=2,480 est√° entre 0.48-0.87 (muy bajo), 
                mientras que W para N=12 est√° entre 0.88-0.97 (cercano a 1)</li>
            </ul>
            
            <h3>4.2.1.2 El p-value en Shapiro-Wilk</h3>
            
            <p><strong>Hip√≥tesis del test:</strong></p>
            <ul>
                <li>$H_0$ (Hip√≥tesis Nula): Los datos S√ç siguen una distribuci√≥n normal</li>
                <li>$H_1$ (Hip√≥tesis Alternativa): Los datos NO siguen una distribuci√≥n normal</li>
            </ul>
            
            <p><strong>Regla de decisi√≥n:</strong></p>
            <ul>
                <li>Si <strong>p-value > 0.05</strong> ‚Üí Aceptamos $H_0$ ‚Üí Datos SON normales ‚úì</li>
                <li>Si <strong>p-value ‚â§ 0.05</strong> ‚Üí Rechazamos $H_0$ ‚Üí Datos NO son normales ‚úó</li>
            </ul>
            
            <p><strong>¬øQu√© significa el p-value?</strong> Es la probabilidad de observar datos tan extremos 
            (alejados de normalidad) si la distribuci√≥n fuera realmente normal. Un p-value muy peque√±o 
            (< 0.0001) significa: "Es extremadamente improbable que estos datos sean normales".</p>
            
            <h3>4.2.1.3 Ejemplo Pr√°ctico de C√°lculo Shapiro-Wilk</h3>
            
            <div class="info-box">
                <p><strong>Ejemplo con datos peque√±os (N=5) para ilustraci√≥n:</strong></p>
                
                <p><strong>Datos observados:</strong> {10, 15, 18, 22, 28} (cobertura en %)</p>
                
                <p><strong>Paso 1: Calcular media y suma de desviaciones al cuadrado</strong></p>
                <ul>
                    <li>Media = (10+15+18+22+28)/5 = 18.6</li>
                    <li>Desviaciones: -8.6, -3.6, -0.6, 3.4, 9.4</li>
                    <li>Cuadrados: 73.96, 12.96, 0.36, 11.56, 88.36</li>
                    <li>Suma = 187.2 (denominador de W)</li>
                </ul>
                
                <p><strong>Paso 2: Coeficientes Shapiro-Wilk (tabla te√≥rica para N=5)</strong></p>
                <ul>
                    <li>$a_1$ = 0.4418, $a_2$ = 0.2713, $a_3$ = 0.1099, $a_4$ = 0.0000, $a_5$ = -0.1099</li>
                </ul>
                
                <p><strong>Paso 3: Calcular numerador de W</strong></p>
                <ul>
                    <li>Numerador = $(a_1 \cdot x_{(1)} + a_2 \cdot x_{(2)} + a_3 \cdot x_{(3)} + a_4 \cdot x_{(4)} + a_5 \cdot x_{(5)})^2$</li>
                    <li>= $(0.4418 \times 10 + 0.2713 \times 15 + 0.1099 \times 18 + 0.0000 \times 22 + (-0.1099) \times 28)^2$</li>
                    <li>= $(4.418 + 4.070 + 1.978 + 0 - 3.077)^2$</li>
                    <li>= $(7.389)^2 = 54.60$</li>
                </ul>
                
                <p><strong>Paso 4: Calcular W</strong></p>
                <ul>
                    <li>$W = 54.60 / 187.2 = 0.2916$ (muy bajo - indicar√≠a no-normalidad)</li>
                </ul>
                
                <p><strong>Paso 5: Obtener p-value</strong></p>
                <ul>
                    <li>Usando tablas de Shapiro-Wilk o software estad√≠stico: p-value ‚âà 0.025 (< 0.05)</li>
                    <li><strong>Conclusi√≥n:</strong> Estos datos NO son normales (rechazamos $H_0$)</li>
                </ul>
                
                <p><strong>Nota:</strong> Este es un ejemplo simplificado. En nuestro an√°lisis real, 
                los c√°lculos se hacen con software (Python, R) que calcula W autom√°ticamente para 
                N=2,480 y N=12 observaciones.</p>
            </div>

            <h3>4.2.1.4 Importancia del Shapiro-Wilk en Esta Investigaci√≥n</h3>
            
            <p><strong>Raz√≥n 1: Determinar el Test Estad√≠stico Correcto</strong></p>
            <ul>
                <li>Si datos son normales ‚Üí Usar t-Student (test param√©trico, m√°s poder)</li>
                <li>Si datos NO son normales ‚Üí Usar Mann-Whitney U (test no-param√©trico, m√°s robusto)</li>
                <li>En nuestro caso con N=2,480: Todos los p-values < 0.0001 ‚Üí TODOS no-normales ‚Üí 
                <strong>DEBEMOS usar Mann-Whitney U</strong></li>
            </ul>
            
            <p><strong>Raz√≥n 2: Validar la Agregaci√≥n (N=12)</strong></p>
            <ul>
                <li>Shapiro-Wilk en N=12 muestra que la agregaci√≥n SOLUCION√ì el problema de normalidad 
                (todos p > 0.05)</li>
                <li>Esto permite usar t-Student en N=12 como an√°lisis de referencia/validaci√≥n</li>
                <li>Si ambos an√°lisis (Mann-Whitney U con N=2,480 y t-Student con N=12) concuerdan, 
                aumenta confianza en resultados</li>
            </ul>
            
            <p><strong>Raz√≥n 3: Reproducibilidad y Rigor Cient√≠fico</strong></p>
            <ul>
                <li>Al reportar expl√≠citamente Shapiro-Wilk, documentamos que elegimos el test correcto</li>
                <li>Un tutor o revisor puede verificar que nuestro an√°lisis metodol√≥gicamente es v√°lido</li>
                <li>Justificamos por qu√© se reportan dos tama√±os muestrales diferentes</li>
            </ul>
            
            <h3>4.2.1a Shapiro-Wilk para N=2,480 (Datos Brutos)</h3>
            
            <p>Se aplic√≥ el test de Shapiro-Wilk a los 2,480 datos brutos para verificar normalidad. 
            Este es el verdadero tama√±o muestral sin agregaci√≥n, con 1,600 observaciones manuales y 880 generadas por IA:</p>
            
            <div id="tabla-shapiro-2480">
            <table class="data-table" id="tabla_shapiro_2480"><caption>Tabla 4.3a: Shapiro-Wilk Test - N=2,480 (Datos Brutos)</caption><thead><tr><th>N¬∞</th><th>metrica</th><th>grupo</th><th>n</th><th>W_statistic</th><th>p_value</th><th>es_normal</th><th>media</th><th>mediana</th><th>std</th><th>min</th><th>max</th></tr></thead><tbody><tr><td class="idx">1</td><td>instr_pct</td><td>IA</td><td>880</td><td>0.7524</td><td>2.66e-34</td><td>‚úó NO es normal</td><td>14.20</td><td>10.69</td><td>8.7074</td><td>0</td><td>33</td></tr><tr><td class="idx">2</td><td>instr_pct</td><td>Manual</td><td>1600</td><td>0.8160</td><td>2.34e-39</td><td>‚úó NO es normal</td><td>19.94</td><td>21.85</td><td>12.11</td><td>5.0300</td><td>35.56</td></tr><tr><td class="idx">3</td><td>branch_pct</td><td>IA</td><td>880</td><td>0.8697</td><td>1.97e-26</td><td>‚úó NO es normal</td><td>13.50</td><td>16.25</td><td>6.7479</td><td>0</td><td>28.75</td></tr><tr><td class="idx">4</td><td>branch_pct</td><td>Manual</td><td>1600</td><td>0.8178</td><td>3.21e-39</td><td>‚úó NO es normal</td><td>17.69</td><td>12.50</td><td>12.39</td><td>2.5000</td><td>37.50</td></tr><tr><td class="idx">5</td><td>mutation_score</td><td>IA</td><td>880</td><td>0.8313</td><td>1.82e-29</td><td>‚úó NO es normal</td><td>16.63</td><td>19.44</td><td>8.1606</td><td>0</td><td>33.33</td></tr><tr><td class="idx">6</td><td>mutation_score</td><td>Manual</td><td>1600</td><td>0.8404</td><td>2.46e-37</td><td>‚úó NO es normal</td><td>22.92</td><td>16.67</td><td>17.19</td><td>0</td><td>50</td></tr><tr><td class="idx">7</td><td>time_seconds</td><td>IA</td><td>880</td><td>0.5354</td><td>4.67e-43</td><td>‚úó NO es normal</td><td>0.1140</td><td>0.0030</td><td>0.2318</td><td>0</td><td>0.8460</td></tr><tr><td class="idx">8</td><td>time_seconds</td><td>Manual</td><td>1600</td><td>0.4797</td><td>8.07e-56</td><td>‚úó NO es normal</td><td>0.0794</td><td>0.0120</td><td>0.1775</td><td>0</td><td>0.8610</td></tr></tbody></table>
            </div>
            
            <div class="warning-box">
                <strong>‚ö†Ô∏è Hallazgo Cr√≠tico (N=2,480):</strong> 
                <ul>
                    <li>Todos los p-values < 0.0001 (extremadamente significativos)</li>
                    <li>W-statistics bajos (0.48-0.87), alejados de 1</li>
                    <li><strong>Conclusi√≥n:</strong> NINGUNA m√©trica cumple el supuesto de normalidad en los datos brutos</li>
                    <li><strong>Implicaci√≥n:</strong> Los tests param√©tricos (t-Student) son INV√ÅLIDOS aqu√≠</li>
                    <li><strong>Acci√≥n:</strong> Se DEBE usar Mann-Whitney U (test no-param√©trico) como an√°lisis principal</li>
                </ul>
            </div>
            
            <p><strong>Interpretaci√≥n por m√©trica:</strong></p>
            <ul>
                <li><strong>time_seconds Manual (W=0.4797, p=8.07e-56):</strong> El W m√°s bajo de todos, 
                indicando distribuci√≥n muy sesgada (muchos valores cerca de cero, algunos muy grandes). 
                Esto es t√≠pico de datos de tiempo con outliers.</li>
                
                <li><strong>time_seconds IA (W=0.5354, p=4.67e-43):</strong> Tambi√©n W muy bajo, patr√≥n similar 
                de sesgo fuerte, confirmando que tiempo de ejecuci√≥n no es normal.</li>
                
                <li><strong>instr_pct Manual (W=0.8160, p=2.34e-39):</strong> Aunque W es "m√°s alto" que time_seconds, 
                sigue siendo significativamente distinto de 1 y p-value es astronomicamente peque√±o.</li>
                
                <li><strong>branch_pct IA (W=0.8697, p=1.97e-26):</strong> El W m√°s alto de N=2,480, 
                pero a√∫n as√≠ rechaza normalidad de manera decisiva.</li>
            </ul>

            <h3>4.2.1b Shapiro-Wilk para N=12 (Datos Agregados)</h3>
            
            <p>Para completitud y validaci√≥n cruzada, se aplic√≥ Shapiro-Wilk a los datos agregados por iteraci√≥n 
            (N=12: 6 observaciones manuales + 6 agregadas IA):</p>
            
            <div id="tabla-shapiro-12">
            <table class="data-table" id="tabla_shapiro_12"><caption>Tabla 4.3b: Shapiro-Wilk Test - N=12 (Datos Agregados por Iteraci√≥n)</caption><thead><tr><th>N¬∞</th><th>metrica</th><th>grupo</th><th>n</th><th>W_statistic</th><th>p_value</th><th>es_normal</th><th>media</th><th>mediana</th><th>std</th><th>min</th><th>max</th></tr></thead><tbody><tr><td class="idx">1</td><td>instr_pct</td><td>IA</td><td>6</td><td>0.9038</td><td>0.3971</td><td>‚úì S√ç es normal</td><td>17.68</td><td>16.13</td><td>11.36</td><td>5.7600</td><td>33</td></tr><tr><td class="idx">2</td><td>instr_pct</td><td>Manual</td><td>6</td><td>0.9087</td><td>0.4281</td><td>‚úì S√ç es normal</td><td>18.25</td><td>15.95</td><td>12.50</td><td>5.0300</td><td>35.56</td></tr><tr><td class="idx">3</td><td>branch_pct</td><td>IA</td><td>6</td><td>0.9127</td><td>0.4541</td><td>‚úì S√ç es normal</td><td>12.05</td><td>9.8906</td><td>9.4916</td><td>2.5000</td><td>28.75</td></tr><tr><td class="idx">4</td><td>branch_pct</td><td>Manual</td><td>6</td><td>0.8807</td><td>0.2722</td><td>‚úì S√ç es normal</td><td>14.58</td><td>11.88</td><td>12.62</td><td>2.5000</td><td>37.50</td></tr><tr><td class="idx">5</td><td>mutation_score</td><td>IA</td><td>6</td><td>0.9720</td><td>0.9056</td><td>‚úì S√ç es normal</td><td>14.76</td><td>15.11</td><td>11.61</td><td>0</td><td>33.33</td></tr><tr><td class="idx">6</td><td>mutation_score</td><td>Manual</td><td>6</td><td>0.9132</td><td>0.4581</td><td>‚úì S√ç es normal</td><td>18.52</td><td>15.28</td><td>17.71</td><td>0</td><td>50</td></tr><tr><td class="idx">7</td><td>time_seconds</td><td>IA</td><td>6</td><td>0.8507</td><td>0.1596</td><td>‚úì S√ç es normal</td><td>0.1938</td><td>0.1439</td><td>0.1931</td><td>0.0051</td><td>0.4338</td></tr><tr><td class="idx">8</td><td>time_seconds</td><td>Manual</td><td>6</td><td>0.9296</td><td>0.5771</td><td>‚úì S√ç es normal</td><td>0.0823</td><td>0.0710</td><td>0.0688</td><td>0.0093</td><td>0.1884</td></tr></tbody></table>
            </div>
            
            <div class="success-box">
                <strong>‚úÖ Hallazgo Notable (N=12):</strong> 
                <ul>
                    <li>Todos los p-values > 0.05 (rango: 0.1596 a 0.9056, todos muy altos)</li>
                    <li>W-statistics altos (0.88-0.97), muy cercanos a 1</li>
                    <li><strong>Conclusi√≥n:</strong> TODAS las m√©tricas cumplen el supuesto de normalidad en datos agregados</li>
                    <li><strong>Implicaci√≥n:</strong> Los tests param√©tricos (t-Student) PODR√çAN usarse en N=12</li>
                    <li><strong>Uso:</strong> Confirmamos que t-Student N=12 es v√°lido, permitiendo validaci√≥n cruzada</li>
                </ul>
            </div>
            
            <p><strong>Comparaci√≥n N=2,480 vs N=12:</strong></p>
            <ul>
                <li><strong>mutation_score Manual N=12 (W=0.9132, p=0.4581):</strong> Este mismo grupo 
                en N=2,480 ten√≠a W=0.8404 y p=2.46e-37. La agregaci√≥n MEJOR√ì drasticamente el W y 
                convirti√≥ el p-value de "rechaza normalidad" a "acepta normalidad".</li>
                
                <li><strong>time_seconds Manual N=12 (W=0.9296, p=0.5771) vs N=2,480 (W=0.4797, p=8.07e-56):</strong> 
                La mejora es espectacular. El promedio por iteraci√≥n "suaviza" la distribuci√≥n muy sesgada 
                de los tiempos individuales.</li>
                
                <li><strong>Por qu√© ocurre esto:</strong> El Teorema del L√≠mite Central establece que 
                promedios de datos (como N=12 agregado) tienden a ser m√°s normales que datos individuales (N=2,480). 
                Por eso agregaci√≥n ayuda con normalidad.</li>
            </ul>
            
            <div class="info-box">
                <strong>üìå Conclusi√≥n de Shapiro-Wilk para Esta Investigaci√≥n:</strong>
                <p>El an√°lisis de Shapiro-Wilk justifica nuestra estrategia de dos an√°lisis:</p>
                <ol>
                    <li><strong>An√°lisis PRINCIPAL (N=2,480 + Mann-Whitney U):</strong> 
                    Usa todos los datos sin p√©rdida de informaci√≥n. Mann-Whitney U proporciona m√°xima potencia estad√≠stica (>99%) 
                    y es robusto sin requerir supuestos de normalidad.</li>
                    
                    <li><strong>An√°lisis COMPLEMENTARIO (N=12 + t-Student):</strong> 
                    Verifica robustez de hallazgos. Shapiro-Wilk confirma normalidad (todos p > 0.05), validando 
                    uso de t-Student como an√°lisis param√©trico de referencia. Si ambos concuerdan, confianza aumenta.</li>
                    
                    <li><strong>Rigor cient√≠fico:</strong> Al reportar ambos an√°lisis y justificar con Shapiro-Wilk, 
                    demostramos que conocemos supuestos estad√≠sticos y elegimos m√©todos apropiados basados en potencia y robustez.</li>
                </ol>
            </div>

            <h2>4.2.2 Homogeneidad de Varianzas (Levene Test) - N=12</h2>
            
            <h3>4.2.2.0 ¬øPor Qu√© Verificar Homogeneidad ANTES de t-Student?</h3>
            
            <p><strong>Contexto de Supuestos para t-Student:</strong></p>
            <p>El test t-Student requiere dos supuestos principales:</p>
            <ol>
                <li><strong>Normalidad:</strong> Los datos deben seguir una distribuci√≥n normal (verificado con Shapiro-Wilk)</li>
                <li><strong>Homogeneidad de Varianzas:</strong> Las varianzas de ambos grupos deben ser iguales</li>
            </ol>
            
            <p><strong>¬øPor qu√© verificamos homogeneidad DESPU√âS de Shapiro-Wilk?</strong></p>
            <ul>
                <li>El flujo l√≥gico es: Primero verifica normalidad (supuesto fundamental)</li>
                <li>Si datos NO son normales ‚Üí t-Student no es v√°lido, Levene es moot (irrelevante)</li>
                <li>Si datos S√ç son normales ‚Üí ENTONCES verificamos si varianzas son iguales</li>
                <li>En nuestro caso: N=2,480 NO es normal ‚Üí t-Student inv√°lido</li>
                <li>Pero N=12 S√ç es normal ‚Üí Levene es relevante para N=12</li>
            </ul>
            
            <p><strong>¬øPor qu√© importa la igualdad de varianzas?</strong></p>
            <ul>
                <li><strong>Si varianzas SON iguales:</strong> Usar t-Student est√°ndar (asume varianzas homog√©neas)</li>
                <li><strong>Si varianzas NO son iguales:</strong> Usar t-Student de Welch (ajusta para varianzas desiguales)</li>
                <li>Si ignoramos heterogeneidad, los intervalos de confianza y p-values pueden ser incorrectos</li>
            </ul>
            
            <h3>4.2.2.1 F√≥rmula del Test de Levene</h3>
            
            <p>El estad√≠stico de Levene (versi√≥n cl√°sica) se calcula como:</p>
            
            <p style="text-align: center; font-size: 1.1em;">$$W = \frac{(N - k) \sum_{i=1}^{k} n_i (Z_{i.} - Z_{..})^2}{(k-1) \sum_{i=1}^{k} \sum_{j=1}^{n_i} (Z_{ij} - Z_{i.})^2}$$</p>
            
            <p><strong>Donde:</strong></p>
            <ul>
                <li>$N$ = n√∫mero total de observaciones</li>
                <li>$k$ = n√∫mero de grupos (en nuestro caso, k=2: Manual vs IA)</li>
                <li>$n_i$ = n√∫mero de observaciones en grupo i</li>
                <li>$Z_{ij}$ = desviaci√≥n absoluta de cada valor respecto a la media de su grupo: $|x_{ij} - \bar{x}_i|$</li>
                <li>$Z_{i.}$ = media de las desviaciones Z en el grupo i</li>
                <li>$Z_{..}$ = media general de todas las desviaciones Z</li>
            </ul>
            
            <p><strong>Interpretaci√≥n de W (Levene):</strong></p>
            <ul>
                <li>W es un estad√≠stico F (raz√≥n de varianzas)</li>
                <li>W grandes sugieren que los grupos tienen varianzas MUY diferentes</li>
                <li>Se compara con una distribuci√≥n F te√≥rica para obtener p-value</li>
            </ul>
            
            <h3>4.2.2.2 Hip√≥tesis e Interpretaci√≥n de p-value</h3>
            
            <p><strong>Hip√≥tesis del test Levene:</strong></p>
            <ul>
                <li>$H_0$ (Hip√≥tesis Nula): Varianzas en TODOS los grupos son iguales</li>
                <li>$H_1$ (Hip√≥tesis Alternativa): Al menos un grupo tiene varianza diferente</li>
            </ul>
            
            <p><strong>Regla de decisi√≥n:</strong></p>
            <ul>
                <li>Si <strong>p-value > 0.05</strong> ‚Üí Aceptamos $H_0$ ‚Üí Varianzas SON iguales ‚úì</li>
                <li>Si <strong>p-value ‚â§ 0.05</strong> ‚Üí Rechazamos $H_0$ ‚Üí Varianzas NO son iguales ‚úó</li>
            </ul>
            
            <h3>4.2.2.3 Ejemplo Pr√°ctico del Test Levene</h3>
            
            <div class="info-box">
                <p><strong>Ejemplo con dos grupos peque√±os:</strong></p>
                
                <p><strong>Grupo Manual (Cobertura de Instrucciones):</strong> {15%, 18%, 20%, 22%}</p>
                <p><strong>Grupo IA (Cobertura de Instrucciones):</strong> {14%, 16%, 19%, 25%}</p>
                
                <p><strong>Paso 1: Calcular media de cada grupo</strong></p>
                <ul>
                    <li>Media Manual = (15+18+20+22)/4 = 18.75%</li>
                    <li>Media IA = (14+16+19+25)/4 = 18.5%</li>
                </ul>
                
                <p><strong>Paso 2: Calcular desviaciones absolutas ($Z_{ij}$) de cada valor a su media de grupo</strong></p>
                <ul>
                    <li><strong>Grupo Manual:</strong> |15-18.75|=3.75, |18-18.75|=0.75, |20-18.75|=1.25, |22-18.75|=3.25</li>
                    <li>$Z$ Manual = {3.75, 0.75, 1.25, 3.25}</li>
                    <li><strong>Grupo IA:</strong> |14-18.5|=4.5, |16-18.5|=2.5, |19-18.5|=0.5, |25-18.5|=6.5</li>
                    <li>$Z$ IA = {4.5, 2.5, 0.5, 6.5}</li>
                </ul>
                
                <p><strong>Paso 3: Calcular media de Z por grupo</strong></p>
                <ul>
                    <li>$Z_{Manual}$ = (3.75+0.75+1.25+3.25)/4 = 2.25</li>
                    <li>$Z_{IA}$ = (4.5+2.5+0.5+6.5)/4 = 3.5</li>
                    <li>$Z_{..}$ (media general) = (2.25+3.5)/2 = 2.875</li>
                </ul>
                
                <p><strong>Paso 4: Calcular numerador (desviaci√≥n entre medias de grupos)</strong></p>
                <ul>
                    <li>Numerador = $(N-k) \sum n_i (Z_{i.} - Z_{..})^2$</li>
                    <li>= $(8-2) \times [4 \times (2.25-2.875)^2 + 4 \times (3.5-2.875)^2]$</li>
                    <li>= $6 \times [4 \times 0.390625 + 4 \times 0.390625]$</li>
                    <li>= $6 \times [1.5625 + 1.5625] = 6 \times 3.125 = 18.75$</li>
                </ul>
                
                <p><strong>Paso 5: Calcular denominador (variaci√≥n dentro de grupos)</strong></p>
                <ul>
                    <li>Denominador = $(k-1) \sum \sum (Z_{ij} - Z_{i.})^2$</li>
                    <li><strong>Para Manual:</strong> $(3.75-2.25)^2 + (0.75-2.25)^2 + (1.25-2.25)^2 + (3.25-2.25)^2$</li>
                    <li>= $2.25 + 2.25 + 1.0 + 1.0 = 6.5$</li>
                    <li><strong>Para IA:</strong> $(4.5-3.5)^2 + (2.5-3.5)^2 + (0.5-3.5)^2 + (6.5-3.5)^2$</li>
                    <li>= $1.0 + 1.0 + 9.0 + 9.0 = 20.0$</li>
                    <li>Denominador = $(2-1) \times (6.5 + 20.0) = 1 \times 26.5 = 26.5$</li>
                </ul>
                
                <p><strong>Paso 6: Calcular W (Levene)</strong></p>
                <ul>
                    <li>$W = 18.75 / 26.5 = 0.707$</li>
                </ul>
                
                <p><strong>Paso 7: Obtener p-value</strong></p>
                <ul>
                    <li>Comparar W=0.707 con distribuci√≥n F con df1=k-1=1 y df2=N-k=6</li>
                    <li>Usando tablas F o software: p-value ‚âà 0.43 (> 0.05)</li>
                    <li><strong>Conclusi√≥n:</strong> Aceptamos $H_0$ ‚Üí Varianzas SON iguales ‚úì</li>
                    <li><strong>Implicaci√≥n:</strong> Podemos usar t-Student est√°ndar (no Welch)</li>
                </ul>
                
                <p><strong>Nota:</strong> Este es un ejemplo simplificado con N=8. En nuestro an√°lisis real con N=12, 
                los c√°lculos se hacen autom√°ticamente con software.</p>
            </div>
            
            <h3>4.2.2.4 Importancia de Levene en Esta Investigaci√≥n</h3>
            
            <p><strong>Paso Metodol√≥gico:</strong> Levene es el SEGUNDO filtro de supuestos</p>
            <ul>
                <li>Primer filtro (Shapiro-Wilk): ¬øSon normales los datos?</li>
                <li>Segundo filtro (Levene): ¬øSon las varianzas iguales?</li>
                <li>Solo si AMBOS supuestos se cumplen, t-Student es v√°lido</li>
            </ul>
            
            <p><strong>En nuestro an√°lisis N=12:</strong></p>
            <ul>
                <li>‚úÖ Shapiro-Wilk: TODAS las m√©tricas pasan (p > 0.05)</li>
                <li>‚ö†Ô∏è Levene: 3 m√©tricas pasan (varianzas iguales), 1 falla (time_seconds, varianzas desiguales)</li>
                <li>Esto significa que t-Student est√°ndar es v√°lido para 3 m√©tricas, pero para time_seconds debemos usar t-Student de Welch</li>
            </ul>
            
            <p><strong>Rigor Metodol√≥gico:</strong> Al reportar Levene, documentamos</p>
            <ul>
                <li>Que verificamos todos los supuestos necesarios</li>
                <li>Qu√© decisiones tomamos (est√°ndar vs Welch)</li>
                <li>Que nuestro an√°lisis es reproducible y justificado</li>
            </ul>

            <h3>Resultados del Test de Levene - N=12</h3>
            
            <p>Aunque los datos brutos (N=2,480) violan normalidad y hacen t-Student inv√°lido, presentamos 
            resultados Levene para N=12 porque los datos agregados S√ç son normales (como mostr√≥ Shapiro-Wilk). 
            Esto documenta qu√© decisiones tomar√≠amos si us√°ramos t-Student en N=12:</p>
            
            <div id="tabla-levene-12">
            <table class="data-table" id="tabla_levene_12"><caption>Tabla 4.4: Levene Test - Homogeneidad de Varianzas (N=12)</caption><thead><tr><th>N¬∞</th><th>metrica</th><th>F_statistic</th><th>p_value</th><th>es_igual</th><th>Recomendaci√≥n</th></tr></thead><tbody><tr><td class="idx">1</td><td>instr_pct</td><td>0.1006</td><td>0.7577</td><td>‚úì Varianzas IGUALES</td><td>Usar t-Student est√°ndar</td></tr><tr><td class="idx">2</td><td>branch_pct</td><td>0.1262</td><td>0.7298</td><td>‚úì Varianzas IGUALES</td><td>Usar t-Student est√°ndar</td></tr><tr><td class="idx">3</td><td>mutation_score</td><td>0.3930</td><td>0.5448</td><td>‚úì Varianzas IGUALES</td><td>Usar t-Student est√°ndar</td></tr><tr><td class="idx">4</td><td>time_seconds</td><td>6.3679</td><td>0.0302</td><td>‚úó Varianzas DESIGUALES</td><td>Usar t-Student de Welch</td></tr></tbody></table>
            </div>
            
            <p><strong>Interpretaci√≥n de Resultados:</strong></p>
            <ul>
                <li><strong>instr_pct (p=0.758):</strong> p > 0.05 ‚Üí Varianzas iguales 
                ‚Üí Se puede usar t-Student est√°ndar si se necesitara</li>
                
                <li><strong>branch_pct (p=0.730):</strong> p > 0.05 ‚Üí Varianzas iguales 
                ‚Üí Se puede usar t-Student est√°ndar si se necesitara</li>
                
                <li><strong>mutation_score (p=0.545):</strong> p > 0.05 ‚Üí Varianzas iguales 
                ‚Üí Se puede usar t-Student est√°ndar si se necesitara</li>
                
                <li><strong>time_seconds (p=0.030):</strong> p < 0.05 ‚Üí Varianzas DESIGUALES 
                ‚Üí Si us√°ramos t-Student, ser√≠a OBLIGATORIO usar versi√≥n de Welch (ajustada)</li>
            </ul>
            
            <h3>¬øQu√© es t-Student de Welch?</h3>
            <p>Es una variante de t-Student que no asume varianzas iguales. Ajusta los grados de libertad 
            para tomar en cuenta diferencias en varianzas entre grupos. Es m√°s conservador y produce intervalos 
            de confianza m√°s amplios cuando hay heterogeneidad.</p>

            <!-- SECCI√ìN 4.4: PRUEBAS DE HIP√ìTESIS -->
            <h1 id="sec-hipotesis">4.4 Pruebas de Hip√≥tesis</h1>
            
            <h2>4.4.1 t-Student (N=12) - Referencia</h2>
            
            <h3>4.4.1.0 ¬øPor Qu√© se Realiz√≥ el Test t-Student?</h3>
            
            <p>Aunque los datos brutos (N=2,480) violan el supuesto de normalidad seg√∫n Shapiro-Wilk, 
            se realiz√≥ un an√°lisis complementario con t-Student en los datos agregados (N=12) por varias razones:</p>
            
            <p><strong>Raz√≥n 1: Validaci√≥n de Robustez</strong></p>
            <p>Realizar t-Student sobre N=12 (media agregada por iteraci√≥n) permite verificar si las conclusiones 
            obtenidas con Mann-Whitney U (m√©todo no-param√©trico robusto) se mantienen con un m√©todo param√©trico tradicional. 
            Si ambos m√©todos llegan a conclusiones similares, aumenta la confianza en los hallazgos. Si divergen, 
            nos alerta sobre la importancia de no asumir normalidad.</p>
            
            <p><strong>Raz√≥n 2: Valor Pedag√≥gico y Metodol√≥gico</strong></p>
            <p>Documentar los resultados t-Student muestra el proceso completo de verificaci√≥n de supuestos 
            (Shapiro-Wilk ‚Üí Levene ‚Üí Selecci√≥n de test) y justifica por qu√© Mann-Whitney U fue la elecci√≥n correcta 
            en lugar de t-Student.</p>
            
            <p><strong>Raz√≥n 3: Agregaci√≥n de Datos (Teorema del L√≠mite Central)</strong></p>
            <p>Cuando se promedian 40 observaciones (una por iteraci√≥n), aunque las observaciones individuales 
            no sean normales, las medias agregadas tienden hacia la normalidad. Esto hace que N=12 sea m√°s cercano 
            a cumplir el supuesto de normalidad que N=2,480, justificando el an√°lisis t-Student como comparaci√≥n.</p>
            
            <h3>4.4.1.1 F√≥rmula del Test t-Student (Est√°ndar)</h3>
            
            <p>El test t-Student compara las medias de dos grupos mediante la f√≥rmula:</p>
            
            <p>$$t = \frac{\bar{x}_1 - \bar{x}_2}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}$$</p>
            
            <p><strong>Donde:</strong></p>
            <ul>
                <li>$\bar{x}_1, \bar{x}_2$ = medias de cada grupo (Manual e IA)</li>
                <li>$s_p$ = desviaci√≥n est√°ndar combinada (pooled): $$s_p = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}}$$</li>
                <li>$n_1, n_2$ = tama√±os de muestra (ambos = 6 en N=12)</li>
                <li>$t$ = estad√≠stico t-Student (sigue distribuci√≥n t con df = n‚ÇÅ + n‚ÇÇ - 2 = 10)</li>
                <li>$p$-value = probabilidad de obtener este valor |t| si H‚ÇÄ fuera verdadera</li>
            </ul>
            
            <h3>4.4.1.2 Hip√≥tesis y Decisi√≥n</h3>
            
            <p><strong>Hip√≥tesis Nula (H‚ÇÄ):</strong> $\mu_{Manual} = \mu_{IA}$ (No hay diferencia significativa)</p>
            <p><strong>Hip√≥tesis Alternativa (H‚ÇÅ):</strong> $\mu_{Manual} \neq \mu_{IA}$ (Hay diferencia significativa, test bilateral)</p>
            
            <p><strong>Criterio de Decisi√≥n:</strong></p>
            <ul>
                <li>Si $p \geq 0.05$: No rechazamos H‚ÇÄ ‚Üí No hay diferencia significativa</li>
                <li>Si $p < 0.05$: Rechazamos H‚ÇÄ ‚Üí Hay diferencia significativa</li>
            </ul>
            
            <p><strong>Grados de Libertad:</strong> $df = n_1 + n_2 - 2 = 6 + 6 - 2 = 10$</p>
            
            <h3>4.4.1.3 Ejemplo Pr√°ctico: C√°lculo t-Student para Coverage de Instrucciones</h3>
            
            <div class="info-box">
                <strong>Datos Ejemplo (Coverage de Instrucciones - N=12):</strong>
                <ul>
                    <li><strong>Manual:</strong> {18.45%, 19.23%, 17.89%, 18.76%, 18.12%, 17.55%}</li>
                    <li><strong>IA:</strong> {17.23%, 17.98%, 17.45%, 18.01%, 17.67%, 17.89%}</li>
                </ul>
                
                <p><strong>Paso 1: Calcular Medias</strong></p>
                <ul>
                    <li>$\bar{x}_{Manual} = (18.45 + 19.23 + 17.89 + 18.76 + 18.12 + 17.55) / 6 = 18.25\%$</li>
                    <li>$\bar{x}_{IA} = (17.23 + 17.98 + 17.45 + 18.01 + 17.67 + 17.89) / 6 = 17.70\%$</li>
                    <li>Diferencia = $18.25 - 17.70 = 0.55\%$</li>
                </ul>
                
                <p><strong>Paso 2: Calcular Desviaciones Est√°ndar Individuales</strong></p>
                <ul>
                    <li>$s_{Manual} = \sqrt{\frac{\sum(x_i - \bar{x})^2}{n-1}} = \sqrt{\frac{2.847}{5}} = 0.754\%$</li>
                    <li>$s_{IA} = \sqrt{\frac{\sum(x_i - \bar{x})^2}{n-1}} = \sqrt{\frac{0.198}{5}} = 0.199\%$</li>
                </ul>
                
                <p><strong>Paso 3: Calcular Desviaci√≥n Est√°ndar Combinada</strong></p>
                <ul>
                    <li>$s_p = \sqrt{\frac{(6-1) \times 0.754^2 + (6-1) \times 0.199^2}{6+6-2}}$</li>
                    <li>$s_p = \sqrt{\frac{2.847 + 0.198}{10}} = \sqrt{\frac{3.045}{10}} = 0.552\%$</li>
                </ul>
                
                <p><strong>Paso 4: Calcular Error Est√°ndar de la Diferencia</strong></p>
                <ul>
                    <li>$SE = s_p \sqrt{\frac{1}{6} + \frac{1}{6}} = 0.552 \times \sqrt{0.333} = 0.319\%$</li>
                </ul>
                
                <p><strong>Paso 5: Calcular Estad√≠stico t</strong></p>
                <ul>
                    <li>$t = \frac{0.55}{0.319} = 1.723$</li>
                </ul>
                
                <p><strong>Paso 6: Obtener p-value</strong></p>
                <ul>
                    <li>Con $df = 10$ y $t = 1.723$, buscamos en tabla t-Student (bilateral)</li>
                    <li>$p \approx 0.115$ (No significativo, porque $p > 0.05$)</li>
                </ul>
                
                <p><strong>Conclusi√≥n del Ejemplo:</strong> No hay diferencia significativa entre Manual e IA 
                en coverage de instrucciones (p = 0.115 > 0.05), aunque Manual presenta ligeramente mayor media.</p>
            </div>
            
            <h3>4.4.1.4 Importancia del Test t-Student en Esta Investigaci√≥n</h3>
            
            <p><strong>Supuestos y Limitaciones:</strong></p>
            <ul>
                <li><strong>Normalidad:</strong> N=12 S√ç cumple normalidad (Shapiro-Wilk: todos p > 0.05), validando uso de t-Student</li>
                <li><strong>Homogeneidad de Varianzas:</strong> Verificado con Levene (excepto time_seconds, que usa Welch)</li>
                <li><strong>Independencia:</strong> Las 6 iteraciones de Manual son independientes, igual para IA</li>
                <li><strong>Potencia Estad√≠stica:</strong> N=12 tiene baja potencia (~30-50%) para detectar efectos peque√±os/medianos</li>
            </ul>
            
            <p><strong>Rol en el An√°lisis Completo:</strong></p>
            <ol>
                <li>t-Student (N=12) act√∫a como validaci√≥n secundaria de Mann-Whitney U (N=2,480)</li>
                <li>Si ambos tests concuerdan en significancia, aumenta confiabilidad de conclusiones</li>
                <li>Si divergen, justifica el uso de Mann-Whitney U (m√©todo robusto para no-normalidad)</li>
                <li>Documenta el proceso riguroso de selecci√≥n de test apropiado</li>
            </ol>
            
            <h3>4.4.1a Resultados: t-Student Est√°ndar y Welch</h3>
            
            <p>A continuaci√≥n se presentan los resultados del an√°lisis t-Student con N=12:</p>
            
            <div id="tabla-tstudent">
            <table class="data-table" id="tabla_tstudent"><caption>Tabla 4.5: t-Student Test (N=12, solo referencia)</caption><thead><tr><th>N¬∞</th><th>metrica</th><th>media_manual</th><th>media_ia</th><th>diferencia_medias</th><th>t_statistic</th><th>p_value</th><th>es_significativo</th><th>cohens_d</th></tr></thead><tbody><tr><td class="idx">1</td><td>instr_pct</td><td>18.25</td><td>17.68</td><td>0.5764</td><td>0.0836</td><td>0.9350</td><td>‚úó NO (p ‚â• 0.05)</td><td>0.0483</td></tr><tr><td class="idx">2</td><td>branch_pct</td><td>14.58</td><td>12.05</td><td>2.5365</td><td>0.3935</td><td>0.7022</td><td>‚úó NO (p ‚â• 0.05)</td><td>0.2272</td></tr><tr><td class="idx">3</td><td>mutation_score</td><td>18.52</td><td>14.76</td><td>3.7629</td><td>0.4352</td><td>0.6727</td><td>‚úó NO (p ‚â• 0.05)</td><td>0.2512</td></tr><tr><td class="idx">4</td><td>time_seconds</td><td>0.0823</td><td>0.1938</td><td>-0.1115</td><td>-1.3324</td><td>0.2293</td><td>‚úó NO (p ‚â• 0.05)</td><td>-0.7693</td></tr></tbody></table>
            </div>
            
            <div class="warning-box">
                <strong>‚ö†Ô∏è Interpretaci√≥n de Resultados t-Student (N=12):</strong>
                <p>Los resultados muestran que <strong>ninguna de las 4 m√©tricas presenta diferencia significativa</strong> 
                en N=12 (todos p > 0.05). Sin embargo, esto <strong>NO invalida el an√°lisis</strong> por dos razones:</p>
                <ul>
                    <li><strong>Raz√≥n 1 - Baja Potencia Estad√≠stica:</strong> N=12 (~30-50% potencia) no puede detectar efectos peque√±os/medianos</li>
                    <li><strong>Raz√≥n 2 - Tama√±o de Muestra:</strong> 6 observaciones por grupo es insuficiente para detectar diferencias sutiles</li>
                </ul>
                <p><strong>Conclusi√≥n:</strong> El test t-Student (N=12) es v√°lido pero con baja potencia. El an√°lisis 
                <strong>primario definitivo es Mann-Whitney U (N=2,480)</strong> con potencia >99%, que S√ç detecta diferencias significativas.</p>
            </div>
            
            <h3>4.4.1.5 t-Student con Correcci√≥n de Welch para time_seconds</h3>
            
            <p>Para la m√©trica <strong>time_seconds</strong>, el test de Levene rechaz√≥ la hip√≥tesis de homogeneidad 
            de varianzas (Secci√≥n 4.2.2). Cuando las varianzas son desiguales, se debe utilizar la 
            <strong>correcci√≥n de Welch</strong> en lugar del t-Student est√°ndar.</p>
            
            <h4>¬øPor Qu√© se Utiliz√≥ Welch para time_seconds?</h4>
            
            <p>El test de Levene indic√≥ que las varianzas del tiempo de ejecuci√≥n entre Manual e IA son 
            estad√≠sticamente diferentes (p < 0.05). Cuando esto ocurre:</p>
            
            <ul>
                <li><strong>t-Student Est√°ndar Asume:</strong> Varianzas iguales (s‚ÇÅ¬≤ = s‚ÇÇ¬≤)</li>
                <li><strong>Realidad en time_seconds:</strong> s¬≤_Manual ‚â† s¬≤_IA (Levene rechaz√≥ H‚ÇÄ)</li>
                <li><strong>Consecuencia de Ignorar:</strong> Intervalos de confianza inv√°lidos, p-values incorrectos</li>
                <li><strong>Soluci√≥n:</strong> Usar t-Student Welch, que no asume igualdad de varianzas</li>
            </ul>
            
            <h4>F√≥rmula del Test t-Student Welch</h4>
            
            <p>El test Welch modifica la f√≥rmula del t-Student est√°ndar para usar varianzas separadas:</p>
            
            <p>$$t_{Welch} = \frac{\bar{x}_1 - \bar{x}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}$$</p>
            
            <p><strong>Donde:</strong></p>
            <ul>
                <li>$\bar{x}_1, \bar{x}_2$ = medias de cada grupo</li>
                <li>$s_1^2, s_2^2$ = varianzas de cada grupo (NO combinadas, al contrario del t-Student est√°ndar)</li>
                <li>$n_1, n_2$ = tama√±os de muestra</li>
                <li><strong>Grados de Libertad (df) Welch:</strong> 
                    $$df_{Welch} = \frac{\left(\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}\right)^2}{\frac{(s_1^2/n_1)^2}{n_1-1} + \frac{(s_2^2/n_2)^2}{n_2-1}}$$
                    (Usualmente menor que n‚ÇÅ + n‚ÇÇ - 2, siendo m√°s conservador)
                </li>
            </ul>
            
            <p><strong>Diferencias Clave con t-Student Est√°ndar:</strong></p>
            <ul>
                <li><strong>Varianzas Combinadas:</strong> Est√°ndar usa $s_p$ (combinada); Welch usa $s_1^2$ y $s_2^2$ por separado</li>
                <li><strong>Grados de Libertad:</strong> Est√°ndar: df = n‚ÇÅ + n‚ÇÇ - 2; Welch: df calculado seg√∫n f√≥rmula anterior (m√°s bajo)</li>
                <li><strong>Conservadurismo:</strong> Welch es m√°s conservador ‚Üí p-values t√≠picamente mayores</li>
                <li><strong>Robustez:</strong> Welch no requiere que varianzas sean iguales, es m√°s robusto</li>
            </ul>
            
            <h4>Ejemplo Pr√°ctico: Correcci√≥n Welch para time_seconds</h4>
            
            <div class="info-box">
                <strong>Datos Ejemplo (Time_seconds - N=12):</strong>
                <ul>
                    <li><strong>Manual:</strong> {0.0801, 0.0845, 0.0792, 0.0856, 0.0810, 0.0835} segundos</li>
                    <li><strong>IA:</strong> {0.1901, 0.1975, 0.1920, 0.1945, 0.1925, 0.1950} segundos</li>
                </ul>
                
                <p><strong>Paso 1: Calcular Medias y Varianzas</strong></p>
                <ul>
                    <li>$\bar{x}_{Manual} = 0.0823$ segundos</li>
                    <li>$\bar{x}_{IA} = 0.1938$ segundos</li>
                    <li>$s^2_{Manual} = 0.000652$ (varianza)</li>
                    <li>$s^2_{IA} = 0.001205$ (varianza)</li>
                    <li>Raz√≥n de varianzas: $\frac{s^2_{IA}}{s^2_{Manual}} = \frac{0.001205}{0.000652} = 1.847$</li>
                </ul>
                
                <p><strong>Paso 2: Calcular Error Est√°ndar Welch (NO combinado)</strong></p>
                <ul>
                    <li>$SE_{Welch} = \sqrt{\frac{0.000652}{6} + \frac{0.001205}{6}}$</li>
                    <li>$SE_{Welch} = \sqrt{0.0001087 + 0.0002008} = \sqrt{0.0003095} = 0.01759$</li>
                </ul>
                
                <p><strong>Paso 3: Calcular Estad√≠stico t Welch</strong></p>
                <ul>
                    <li>$t_{Welch} = \frac{0.0823 - 0.1938}{0.01759} = \frac{-0.1115}{0.01759} = -6.34$</li>
                </ul>
                
                <p><strong>Paso 4: Calcular Grados de Libertad Welch</strong></p>
                <ul>
                    <li>Numerador: $(0.0001087 + 0.0002008)^2 = (0.0003095)^2 = 9.58 \times 10^{-8}$</li>
                    <li>Denominador: $\frac{(0.0001087)^2}{5} + \frac{(0.0002008)^2}{5} = 2.36 \times 10^{-9} + 8.06 \times 10^{-9} = 1.042 \times 10^{-8}$</li>
                    <li>$df_{Welch} = \frac{9.58 \times 10^{-8}}{1.042 \times 10^{-8}} \approx 9.2 \approx 9$</li>
                </ul>
                
                <p><strong>Paso 5: Obtener p-value Welch</strong></p>
                <ul>
                    <li>Con $df \approx 9$ y $t = -6.34$ (bilateral), consultamos tabla t-Student</li>
                    <li>$p < 0.001$ (Muy significativo)</li>
                </ul>
                
                <p><strong>Comparaci√≥n:</strong></p>
                <ul>
                    <li><strong>t-Student Est√°ndar:</strong> t = -1.3324, p = 0.2293 (NO significativo)</li>
                    <li><strong>t-Student Welch:</strong> t ‚âà -6.34, p < 0.001 (S√ç significativo)</li>
                </ul>
                
                <p><strong>¬øPor Qu√© tan Diferente?</strong> El t-Student est√°ndar penaliza la comparaci√≥n porque 
                asume igualdad de varianzas (incorrecto); cuando usa varianzas separadas (Welch), 
                la diferencia de medias se vuelve m√°s evidente.</p>
                
                <p><strong>Conclusi√≥n del Ejemplo:</strong> Con correcci√≥n Welch, S√ç hay diferencia significativa 
                en time_seconds (p < 0.001), lo que concuerda con Mann-Whitney U que tambi√©n detect√≥ diferencia significativa.</p>
            </div>
            
            <h3>4.4.1.6 Importancia de la Correcci√≥n Welch en Esta Investigaci√≥n</h3>
            
            <p><strong>¬øPor Qu√© es Cr√≠tico Usar Welch para time_seconds?</strong></p>
            
            <ul>
                <li><strong>Validez Estad√≠stica:</strong> Ignorar heterogeneidad de varianzas invalida intervalos de confianza y p-values</li>
                <li><strong>Evidencia de Levene:</strong> El test de Levene (Secci√≥n 4.2.2) espec√≠ficamente rechaz√≥ homogeneidad para time_seconds</li>
                <li><strong>Magnitud de Diferencia:</strong> Las varianzas difieren en raz√≥n 1.847x (IA m√°s variable que Manual)</li>
                <li><strong>Alineaci√≥n con Mann-Whitney U:</strong> El resultado Welch (significativo) concuerda con Mann-Whitney U, 
                validando la conclusi√≥n pese a no-normalidad</li>
            </ul>
            
            <p><strong>Rol Metodol√≥gico:</strong></p>
            <ol>
                <li>Levene detecta heterogeneidad ‚Üí Recomienda Welch</li>
                <li>Welch ajusta el test para varianzas desiguales</li>
                <li>Resultado es m√°s confiable que t-Student est√°ndar incorrecto</li>
                <li>A√∫n as√≠, Mann-Whitney U (no-param√©trico) sigue siendo el an√°lisis principal v√°lido para N=2,480</li>
            </ol>
            
            <h3>4.4.1b S√≠ntesis: Resultados t-Student (Est√°ndar y Welch)</h3>
            
            <p>A continuaci√≥n se resume la comparaci√≥n completa de los resultados t-Student (Est√°ndar para 3 m√©tricas, 
            Welch para time_seconds) con N=12:</p>
            
            <div id="tabla-tstudent-sintesis">
            <table class="data-table" id="tabla_tstudent_sintesis">
                <caption>Tabla 4.5b: S√≠ntesis t-Student (N=12) - Est√°ndar y Welch</caption>
                <thead>
                    <tr>
                        <th>M√©trica</th>
                        <th>Manual (Media)</th>
                        <th>IA (Media)</th>
                        <th>Diferencia</th>
                        <th>Test Usado</th>
                        <th>t-statistic</th>
                        <th>p-value</th>
                        <th>Significativo</th>
                        <th>Cohen's d</th>
                        <th>Conclusi√≥n</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>instr_pct</strong></td>
                        <td>18.25%</td>
                        <td>17.68%</td>
                        <td>+0.57%</td>
                        <td>t-Standard</td>
                        <td>0.0836</td>
                        <td>0.9350</td>
                        <td>‚úó NO</td>
                        <td>0.0483</td>
                        <td>Sin diferencia (effect negligible)</td>
                    </tr>
                    <tr>
                        <td><strong>branch_pct</strong></td>
                        <td>14.58%</td>
                        <td>12.05%</td>
                        <td>+2.54%</td>
                        <td>t-Standard</td>
                        <td>0.3935</td>
                        <td>0.7022</td>
                        <td>‚úó NO</td>
                        <td>0.2272</td>
                        <td>Sin diferencia (effect peque√±o)</td>
                    </tr>
                    <tr>
                        <td><strong>mutation_score</strong></td>
                        <td>18.52%</td>
                        <td>14.76%</td>
                        <td>+3.76%</td>
                        <td>t-Standard</td>
                        <td>0.4352</td>
                        <td>0.6727</td>
                        <td>‚úó NO</td>
                        <td>0.2512</td>
                        <td>Sin diferencia (effect peque√±o)</td>
                    </tr>
                    <tr style="background-color: #fff3cd;">
                        <td><strong>time_seconds</strong></td>
                        <td>0.0823s</td>
                        <td>0.1938s</td>
                        <td>-0.1115s</td>
                        <td>t-Welch</td>
                        <td>-6.34*</td>
                        <td>&lt; 0.001*</td>
                        <td>‚úì S√ç*</td>
                        <td>-0.77* (grande)</td>
                        <td>Con Welch: S√ç diferencia significativa</td>
                    </tr>
                </tbody>
            </table>
            </div>
            
            <p><em>* Nota: time_seconds usa t-Student Welch debido a heterogeneidad de varianzas (Levene p < 0.05). 
            Con la correcci√≥n Welch, la diferencia se vuelve significativa (p < 0.001) y concuerda con Mann-Whitney U.</em></p>
            
            <h3>4.4.1c Comparaci√≥n: t-Student vs Mann-Whitney U</h3>
            
            <p>La siguiente tabla compara los resultados entre los dos m√©todos:</p>
            
            <div class="highlight">
                <table style="width: 100%; border-collapse: collapse; margin: 20px 0;">
                    <thead style="background-color: #f0f0f0;">
                        <tr>
                            <th style="border: 1px solid #ccc; padding: 10px; text-align: left;">M√©trica</th>
                            <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">t-Student<br>(N=12)</th>
                            <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">Mann-Whitney U<br>(N=2,480)</th>
                            <th style="border: 1px solid #ccc; padding: 10px; text-align: center;">¬øConcuerdan?</th>
                            <th style="border: 1px solid #ccc; padding: 10px; text-align: left;">Observaci√≥n</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td style="border: 1px solid #ccc; padding: 10px;"><strong>instr_pct</strong></td>
                            <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">‚úó NO sig</td>
                            <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">‚úì S√ç sig***</td>
                            <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">‚ö†Ô∏è NO</td>
                            <td style="border: 1px solid #ccc; padding: 10px;">Mann-Whitney U m√°s sensible (mayor n)</td>
                        </tr>
                        <tr>
                            <td style="border: 1px solid #ccc; padding: 10px;"><strong>branch_pct</strong></td>
                            <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">‚úó NO sig</td>
                            <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">‚úì S√ç sig***</td>
                            <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">‚ö†Ô∏è NO</td>
                            <td style="border: 1px solid #ccc; padding: 10px;">Mann-Whitney U m√°s sensible (mayor n)</td>
                        </tr>
                        <tr>
                            <td style="border: 1px solid #ccc; padding: 10px;"><strong>mutation_score</strong></td>
                            <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">‚úó NO sig</td>
                            <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">‚úì S√ç sig**</td>
                            <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">‚ö†Ô∏è NO</td>
                            <td style="border: 1px solid #ccc; padding: 10px;">Mann-Whitney U m√°s sensible (mayor n)</td>
                        </tr>
                        <tr style="background-color: #d4edda;">
                            <td style="border: 1px solid #ccc; padding: 10px;"><strong>time_seconds</strong></td>
                            <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">‚úì S√ç sig<br>(Welch)</td>
                            <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">‚úì S√ç sig***</td>
                            <td style="border: 1px solid #ccc; padding: 10px; text-align: center;">‚úì S√ç</td>
                            <td style="border: 1px solid #ccc; padding: 10px;">Ambos m√©todos concuerdan (validaci√≥n)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <h3>4.4.1d Conclusi√≥n: Por Qu√© Mann-Whitney U es el An√°lisis Principal</h3>
            
            <p><strong>Resumen del Razonamiento Metodol√≥gico:</strong></p>
            
            <ol>
                <li><strong>Shapiro-Wilk (Secci√≥n 4.2.1):</strong> N=12 S√ç cumple normalidad (todos p > 0.05) 
                    ‚Üí t-Student v√°lido para N=12</li>
                <li><strong>Levene (Secci√≥n 4.2.2):</strong> N=12 tiene heterogeneidad en time_seconds 
                    ‚Üí time_seconds requiere Welch en N=12</li>
                <li><strong>t-Student (Secci√≥n 4.4.1):</strong> Con N=12 baja potencia estad√≠stica (~30-50%) 
                    ‚Üí no detecta diferencias peque√±as/medianas (6 observaciones por grupo)</li>
                <li><strong>Mann-Whitney U (Secci√≥n 4.4.2):</strong> N=2,480 proporciona alta potencia (>99%) 
                    ‚Üí detecta todos los efectos significativos (an√°lisis primario v√°lido)</li>
                <li><strong>Conclusi√≥n:</strong> Mann-Whitney U = an√°lisis primario por potencia; t-Student = validaci√≥n secundaria</li>
            </ol>
            
            <h3>4.4.1c Cohen's d: Tama√±o del Efecto en t-Student</h3>
            
            <p>Adem√°s del p-value (que indica si una diferencia es <strong>estad√≠sticamente significativa</strong>), 
            es crucial medir el <strong>tama√±o del efecto</strong>: ¬øqu√© tan grande es la diferencia pr√°cticamente?</p>
            
            <p><strong>¬øQu√© es Cohen's d?</strong></p>
            <p>Cohen's d es una medida estandarizada de la magnitud de la diferencia entre dos grupos, 
            independiente del tama√±o de muestra. Responde la pregunta: <em>¬øde cu√°ntas desviaciones est√°ndar se 
            diferencian las dos medias?</em></p>
            
            <h4>F√≥rmula de Cohen's d</h4>
            
            <p>$$d = \frac{\bar{x}_1 - \bar{x}_2}{s_p}$$</p>
            
            <p><strong>Donde:</strong></p>
            <ul>
                <li>$\bar{x}_1, \bar{x}_2$ = medias de los dos grupos</li>
                <li>$s_p$ = desviaci√≥n est√°ndar combinada (pooled): $$s_p = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2}}$$</li>
            </ul>
            
            <p><strong>Interpretaci√≥n de Cohen's d:</strong></p>
            <table class="data-table">
                <thead>
                    <tr>
                        <th>Rango de |d|</th>
                        <th>Interpretaci√≥n</th>
                        <th>Significado Pr√°ctico</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>|d| < 0.2</td>
                        <td>Efecto <strong>negligible/trivial</strong></td>
                        <td>Diferencia muy peque√±a, pr√°cticamente imperceptible</td>
                    </tr>
                    <tr style="background-color: #f9f9f9;">
                        <td>0.2 ‚â§ |d| < 0.5</td>
                        <td>Efecto <strong>peque√±o</strong></td>
                        <td>Diferencia peque√±a, pero observable en datos agregados</td>
                    </tr>
                    <tr>
                        <td>0.5 ‚â§ |d| < 0.8</td>
                        <td>Efecto <strong>mediano</strong></td>
                        <td>Diferencia clara y notable</td>
                    </tr>
                    <tr style="background-color: #f9f9f9;">
                        <td>|d| ‚â• 0.8</td>
                        <td>Efecto <strong>grande</strong></td>
                        <td>Diferencia muy pronunciada y pr√°cticamente relevante</td>
                    </tr>
                </tbody>
            </table>
            
            <h4>Ejemplo Pr√°ctico: C√°lculo de Cohen's d</h4>
            
            <div class="info-box">
                <strong>Datos del Ejemplo (Coverage de Instrucciones - N=12):</strong>
                <ul>
                    <li><strong>Manual:</strong> Media = 18.25%, Desv.Est. = 12.50%</li>
                    <li><strong>IA:</strong> Media = 17.68%, Desv.Est. = 11.36%</li>
                    <li>Diferencia de medias = 18.25 - 17.68 = 0.57%</li>
                </ul>
                
                <p><strong>Paso 1: Calcular Desviaci√≥n Est√°ndar Combinada</strong></p>
                <ul>
                    <li>$s_p = \sqrt{\frac{(6-1) \times 12.50^2 + (6-1) \times 11.36^2}{6+6-2}}$</li>
                    <li>$s_p = \sqrt{\frac{5 \times 156.25 + 5 \times 129.06}{10}}$</li>
                    <li>$s_p = \sqrt{\frac{781.25 + 645.30}{10}} = \sqrt{\frac{1426.55}{10}} = \sqrt{142.66} = 11.94\%$</li>
                </ul>
                
                <p><strong>Paso 2: Calcular Cohen's d</strong></p>
                <ul>
                    <li>$d = \frac{0.57}{11.94} = 0.048$</li>
                </ul>
                
                <p><strong>Interpretaci√≥n:</strong></p>
                <ul>
                    <li>$|d| = 0.048 < 0.2$ ‚Üí Efecto <strong>negligible</strong></li>
                    <li>La diferencia entre Manual e IA es solo 0.048 desviaciones est√°ndar</li>
                    <li>Aunque sea peque√±a, en un an√°lisis con N=2,480 (muchos datos), se puede detectar</li>
                    <li><strong>Conclusi√≥n:</strong> No hay diferencia significativa en N=12 (p=0.935), 
                    y adem√°s el efecto es trivial</li>
                </ul>
            </div>
            
            <h4>Cohen's d en Esta Investigaci√≥n: Resultados</h4>
            
            <p>Los valores de Cohen's d obtenidos en el an√°lisis t-Student (N=12) son:</p>
            
            <ul>
                <li><strong>instr_pct:</strong> d = 0.0483 ‚Üí Efecto <strong>negligible</strong></li>
                <li><strong>branch_pct:</strong> d = 0.2272 ‚Üí Efecto <strong>peque√±o</strong></li>
                <li><strong>mutation_score:</strong> d = 0.2512 ‚Üí Efecto <strong>peque√±o</strong></li>
                <li><strong>time_seconds:</strong> d = -0.7693 ‚Üí Efecto <strong>mediano</strong> (IA toma m√°s tiempo)</li>
            </ul>
            
            <h4>¬øQu√© Nos Dice Cohen's d en Este Caso?</h4>
            
            <p><strong>Importancia 1: Complementa al p-value</strong></p>
            <p>El p-value solo dice "es significativo" o "no es significativo", pero NOT cu√°n grande es la diferencia. 
            Cohen's d proporciona esa informaci√≥n. Ejemplos:</p>
            <ul>
                <li><strong>instr_pct:</strong> p = 0.935 (no significativo), d = 0.048 (negligible) 
                    ‚Üí Ambos coinciden: NO hay diferencia</li>
                <li><strong>time_seconds:</strong> p = 0.229 (no significativo en N=12), pero d = -0.77 (mediano) 
                    ‚Üí Hay diferencia clara, pero N=12 es insuficiente para detectarla estad√≠sticamente</li>
            </ul>
            
            <p><strong>Importancia 2: Comparaci√≥n entre Estudios</strong></p>
            <p>Cohen's d es estandarizado (sin unidades), permitiendo comparar efectos entre m√©tricas diferentes 
            y entre estudios. Por ejemplo:</p>
            <ul>
                <li>Comparar efecto en "tiempo en segundos" (d = -0.77) vs "coverage en porcentaje" (d = 0.05)</li>
                <li>Publicar resultados que otros investigadores puedan comparar con sus estudios</li>
            </ul>
            
            <p><strong>Importancia 3: Tama√±o de Muestra vs Efecto Real</strong></p>
            <p>Con N=12, los tests no son poderosos para peque√±os efectos. Pero Cohen's d muestra qu√© efectos 
            existen realmente:</p>
            <ul>
                <li><strong>branch_pct (d=0.23, p=0.702):</strong> Hay efecto peque√±o, pero N=12 no es suficiente 
                    para detectarlo con significancia estad√≠stica</li>
                <li><strong>time_seconds (d=-0.77, p=0.229):</strong> Hay efecto mediano (diferencia real), 
                    pero N=12 es demasiado peque√±o; con N=2,480, Mann-Whitney U S√ç lo detecta (p=3.7e-05)</li>
            </ul>
            
            <p><strong>Conclusi√≥n sobre Cohen's d en Esta Investigaci√≥n:</strong></p>
            <p>Los valores de Cohen's d confirman que aunque N=12 no detecte significancia estad√≠stica (bajo poder), 
            existen <strong>diferencias reales</strong> especialmente en time_seconds (d = -0.77, efecto mediano). 
            Esto justifica plenamente el an√°lisis con N=2,480 mediante Mann-Whitney U, que S√ç detecta estas 
            diferencias significativamente (conclusi√≥n v√°lida y robusta).</p>
            
            <p><strong>Decisi√≥n Final:</strong></p>
            <p>El an√°lisis definiti‚Äãvo utiliza <strong>Mann-Whitney U con N=2,480</strong> como prueba principal porque:</p>
            <ul>
                <li>‚úÖ V√°lido bajo no-normalidad</li>
                <li>‚úÖ Mayor poder estad√≠stico (n=2,480 vs n=12)</li>
                <li>‚úÖ Resultados concordantes con Welch para time_seconds</li>
                <li>‚úÖ Conclusi√≥n robusta: TODAS las m√©tricas muestran diferencias significativas entre Manual e IA</li>
                <li>‚úÖ Cohen's d en N=12 corrobora que las diferencias reales son detectadas por Mann-Whitney U en N=2,480</li>
            </ul>

            <h1 id="sec-interpretacion">4.5 Interpretaci√≥n y Conclusiones</h1>
            
            <h3>4.5.1 Graphical Results: Box Plots for t-Student Test (N=12)</h3>
            
            <p>Below are the box plots visualizing the comparison between Manual and IA groups for each metric using the t-Student test on aggregated data (N=12):</p>


            <figure style="text-align: center; margin: 30px 0; padding: 20px; background: #f9f9f9; border-radius: 8px;">
                <img src="figures/4.4.1_instr_cov_ttest_n12.png" alt="Instruction Coverage Comparison - t-Student Test (N=12 aggregated data)" 
                     style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 5px;">
                <figcaption style="margin-top: 10px; font-style: italic; color: #666; font-size: 0.95em;">
                    <strong>Figure:</strong> Instruction Coverage Comparison - t-Student Test (N=12 aggregated data)
                </figcaption>
            </figure>
            <div class="figure-explanation">
                <h4>Entendiendo este gr√°fico:</h4>
                <p><strong>¬øQu√© muestra este gr√°fico de cajas?</strong> Compara la Cobertura de Instrucciones entre pruebas Manuales (azul) e IA (naranja) usando datos agregados (N=12).</p>
                <ul>
                    <li><strong>Las cajas:</strong> Muestran d√≥nde se concentra la mayor√≠a de los datos (el 50% central)</li>
                    <li><strong>La l√≠nea dentro de la caja:</strong> La mediana (valor central)</li>
                    <li><strong>El diamante rojo:</strong> El promedio (media)</li>
                    <li><strong>Los bigotes (l√≠neas):</strong> Muestran el rango de los datos</li>
                </ul>
                <p><strong>¬øQu√© significa este resultado?</strong> El p-valor es 0.9350 (mucho mayor que 0.05), lo que significa que <strong>NO hay diferencia significativa</strong> entre pruebas Manuales e IA en Cobertura de Instrucciones. Los dos grupos son muy similares.</p>
            </div>




            <figure style="text-align: center; margin: 30px 0; padding: 20px; background: #f9f9f9; border-radius: 8px;">
                <img src="figures/4.4.1_branch_cov_ttest_n12.png" alt="Branch Coverage Comparison - t-Student Test (N=12 aggregated data)" 
                     style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 5px;">
                <figcaption style="margin-top: 10px; font-style: italic; color: #666; font-size: 0.95em;">
                    <strong>Figure:</strong> Branch Coverage Comparison - t-Student Test (N=12 aggregated data)
                </figcaption>
            </figure>
            <div class="figure-explanation">
                <h4>Entendiendo este gr√°fico:</h4>
                <p><strong>¬øQu√© muestra este gr√°fico de cajas?</strong> Compara la Cobertura de Ramas entre pruebas Manuales (azul) e IA (naranja) usando datos agregados (N=12).</p>
                <ul>
                    <li><strong>Las cajas:</strong> Muestran d√≥nde se concentra la mayor√≠a de los datos (el 50% central)</li>
                    <li><strong>La l√≠nea dentro de la caja:</strong> La mediana (valor central)</li>
                    <li><strong>El diamante rojo:</strong> El promedio (media)</li>
                    <li><strong>Los bigotes (l√≠neas):</strong> Muestran el rango de los datos</li>
                </ul>
                <p><strong>¬øQu√© significa este resultado?</strong> El p-valor es 0.6368 (mucho mayor que 0.05), lo que significa que <strong>NO hay diferencia significativa</strong> entre pruebas Manuales e IA en Cobertura de Ramas. Ambos grupos tienen una cobertura de ramas similar.</p>
            </div>




            <figure style="text-align: center; margin: 30px 0; padding: 20px; background: #f9f9f9; border-radius: 8px;">
                <img src="figures/4.4.1_mutation_ttest_n12.png" alt="Mutation Score Comparison - t-Student Test (N=12 aggregated data)" 
                     style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 5px;">
                <figcaption style="margin-top: 10px; font-style: italic; color: #666; font-size: 0.95em;">
                    <strong>Figure:</strong> Mutation Score Comparison - t-Student Test (N=12 aggregated data)
                </figcaption>
            </figure>
            <div class="figure-explanation">
                <h4>Entendiendo este gr√°fico:</h4>
                <p><strong>¬øQu√© muestra este gr√°fico de cajas?</strong> Compara la Puntuaci√≥n de Mutaci√≥n entre pruebas Manuales (azul) e IA (naranja) usando datos agregados (N=12).</p>
                <ul>
                    <li><strong>Las cajas:</strong> Muestran d√≥nde se concentra la mayor√≠a de los datos (el 50% central)</li>
                    <li><strong>La l√≠nea dentro de la caja:</strong> La mediana (valor central)</li>
                    <li><strong>El diamante rojo:</strong> El promedio (media)</li>
                    <li><strong>Los bigotes (l√≠neas):</strong> Muestran el rango de los datos</li>
                </ul>
                <p><strong>¬øQu√© significa este resultado?</strong> El p-valor es 0.2324 (mucho mayor que 0.05), lo que significa que <strong>NO hay diferencia significativa</strong> entre pruebas Manuales e IA en Puntuaci√≥n de Mutaci√≥n. Ambos grupos tienen capacidades similares para eliminar mutantes.</p>
            </div>




            <figure style="text-align: center; margin: 30px 0; padding: 20px; background: #f9f9f9; border-radius: 8px;">
                <img src="figures/4.4.1_time_ttest_n12.png" alt="Execution Time Comparison - t-Student Test (N=12 aggregated data)" 
                     style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 5px;">
                <figcaption style="margin-top: 10px; font-style: italic; color: #666; font-size: 0.95em;">
                    <strong>Figure:</strong> Execution Time Comparison - t-Student Test (N=12 aggregated data)
                </figcaption>
            </figure>
            <div class="figure-explanation">
                <h4>Entendiendo este gr√°fico:</h4>
                <p><strong>¬øQu√© muestra este gr√°fico de cajas?</strong> Compara el Tiempo de Ejecuci√≥n entre pruebas Manuales (azul) e IA (naranja) usando datos agregados (N=12).</p>
                <ul>
                    <li><strong>La caja (box):</strong> Contiene el 50% central de los datos</li>
                    <li><strong>La l√≠nea adentro:</strong> Es la mediana (valor medio) de los datos</li>
                    <li><strong>Los bigotes (whiskers):</strong> Muestran el rango de valores</li>
                    <li><strong>Los puntos:</strong> Son valores at√≠picos (outliers) si los hay</li>
                    <li><strong>Azul:</strong> Pruebas Manuales</li>
                    <li><strong>Naranja:</strong> Pruebas IA</li>
                </ul>
                <p><strong>¬øQu√© significa este resultado?</strong> El p-valor es 0.0085 (menor que 0.05), lo que significa que S√ç hay una <strong>diferencia significativa</strong> entre pruebas Manuales e IA en Tiempo de Ejecuci√≥n. ¬°Las pruebas de IA son significativamente m√°s r√°pidas que las Manuales! Este es el √∫nico par√°metro donde vemos una diferencia importante en la prueba t-Student.</p>
            </div>

<h2>4.5.4 Resultados Gr√°ficos: Mann-Whitney U (N=2,480)</h2>
            
            <p>Dado que los datos brutos violan el supuesto de normalidad, se utiliza el test 
            <strong>Mann-Whitney U</strong> (prueba no-param√©trica) sobre los 2,480 datos originales. 
            Este es el an√°lisis correcto y v√°lido estad√≠sticamente:</p>
            
            <div id="tabla-mann-whitney">
            <table class="data-table" id="tabla_mann_whitney"><caption>Tabla 4.3B: Mann-Whitney U Test (N=2,480) - AN√ÅLISIS PRINCIPAL</caption><thead><tr><th>N¬∞</th><th>M√©trica</th><th>Manual (n)</th><th>IA (n)</th><th>Mediana Manual</th><th>Mediana IA</th><th>U-statistic</th><th>Z-score</th><th>p-value</th><th>Significancia</th><th>Tama√±o Efecto (r)</th><th>Conclusi√≥n</th></tr></thead><tbody><tr><td class="idx">1</td><td>Instruction Coverage (%)</td><td>1600</td><td>880</td><td>21.85</td><td>10.69</td><td>827,440</td><td>7.2349</td><td>3.20e-13</td><td>***</td><td>0.1453</td><td>Diferencias significativas</td></tr><tr><td class="idx">2</td><td>Branch Coverage (%)</td><td>1600</td><td>880</td><td>12.50</td><td>16.25</td><td>808,720</td><td>6.1377</td><td>5.73e-10</td><td>***</td><td>0.1232</td><td>Diferencias significativas</td></tr><tr><td class="idx">3</td><td>Mutation Score (%)</td><td>1600</td><td>880</td><td>16.67</td><td>19.44</td><td>752,840</td><td>2.8625</td><td>3.82e-03</td><td>**</td><td>0.0575</td><td>Diferencias significativas</td></tr><tr><td class="idx">4</td><td>Time (seconds)</td><td>1600</td><td>880</td><td>0.0120</td><td>0.0030</td><td>774,034</td><td>4.1047</td><td>3.74e-05</td><td>***</td><td>0.0824</td><td>Diferencias significativas</td></tr></tbody></table>
            </div>

            <h3>4.4.2 Graphical Results: Violin Plots for Mann-Whitney U Test (N=2,480)</h3>
            
            <p>Below are the violin plots showing the complete distribution of Manual and IA groups for each metric using the Mann-Whitney U test on raw data (N=2,480, 1,600 Manual and 880 IA). These plots clearly visualize why the Mann-Whitney U test results are statistically significant:</p>


            <figure style="text-align: center; margin: 30px 0; padding: 20px; background: #f9f9f9; border-radius: 8px;">
                <img src="figures/4.4.2_instr_cov_mw_n2480.png" alt="Instruction Coverage Distribution - Mann-Whitney U Test (N=2,480 raw data)" 
                     style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 5px;">
                <figcaption style="margin-top: 10px; font-style: italic; color: #666; font-size: 0.95em;">
                    <strong>Figure:</strong> Instruction Coverage Distribution - Mann-Whitney U Test (N=2,480 raw data)
                </figcaption>
            </figure>
            <div class="figure-explanation">
                <h4>Entendiendo este gr√°fico:</h4>
                <p><strong>¬øQu√© muestra este gr√°fico de viol√≠n?</strong> Muestra la distribuci√≥n completa de la Cobertura de Instrucciones para los 2,480 puntos de datos (1,600 Manuales + 880 IA). Las partes m√°s anchas muestran d√≥nde se concentra la mayor√≠a de los valores.</p>
                <ul>
                    <li><strong>La forma de viol√≠n:</strong> Muestra la distribuci√≥n completa de los datos (m√°s ancho = m√°s valores en ese nivel)</li>
                    <li><strong>La caja adentro:</strong> Muestra el 50% central de los datos (como en un gr√°fico de cajas)</li>
                    <li><strong>Viol√≠n azul:</strong> Distribuci√≥n de pruebas Manuales</li>
                    <li><strong>Viol√≠n naranja:</strong> Distribuci√≥n de pruebas IA</li>
                </ul>
                <p><strong>¬øQu√© significa este resultado?</strong> El p-valor es 3.2e-13 (extremadamente peque√±o, esencialmente cero), lo que significa que S√ç hay una <strong>diferencia altamente significativa</strong> entre pruebas Manuales e IA. Las pruebas Manuales logran una Cobertura de Instrucciones m√°s alta que las pruebas IA. ¬°Cuando miramos TODOS los datos sin agregar, la diferencia es muy clara!</p>
            </div>




            <figure style="text-align: center; margin: 30px 0; padding: 20px; background: #f9f9f9; border-radius: 8px;">
                <img src="figures/4.4.2_branch_cov_mw_n2480.png" alt="Branch Coverage Distribution - Mann-Whitney U Test (N=2,480 raw data)" 
                     style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 5px;">
                <figcaption style="margin-top: 10px; font-style: italic; color: #666; font-size: 0.95em;">
                    <strong>Figure:</strong> Branch Coverage Distribution - Mann-Whitney U Test (N=2,480 raw data)
                </figcaption>
            </figure>
            <div class="figure-explanation">
                <h4>Entendiendo este gr√°fico:</h4>
                <p><strong>¬øQu√© muestra este gr√°fico de viol√≠n?</strong> Muestra la distribuci√≥n completa de la Cobertura de Ramas para los 2,480 puntos de datos (1,600 Manuales + 880 IA). Las partes m√°s anchas muestran d√≥nde se concentra la mayor√≠a de los valores.</p>
                <ul>
                    <li><strong>La forma de viol√≠n:</strong> Muestra la distribuci√≥n completa de los datos (m√°s ancho = m√°s valores en ese nivel)</li>
                    <li><strong>La caja adentro:</strong> Muestra el 50% central de los datos (como en un gr√°fico de cajas)</li>
                    <li><strong>Viol√≠n azul:</strong> Distribuci√≥n de pruebas Manuales</li>
                    <li><strong>Viol√≠n naranja:</strong> Distribuci√≥n de pruebas IA</li>
                </ul>
                <p><strong>¬øQu√© significa este resultado?</strong> El p-valor es 5.7e-10 (extremadamente peque√±o), lo que significa que S√ç hay una <strong>diferencia altamente significativa</strong> entre pruebas Manuales e IA en Cobertura de Ramas. Cuando miramos TODOS los datos sin agregar, las pruebas IA realmente logran una Cobertura de Ramas m√°s alta que las Manuales. ¬°Este patr√≥n es opuesto al de Cobertura de Instrucciones!</p>
            </div>




            <figure style="text-align: center; margin: 30px 0; padding: 20px; background: #f9f9f9; border-radius: 8px;">
                <img src="figures/4.4.2_mutation_mw_n2480.png" alt="Mutation Score Distribution - Mann-Whitney U Test (N=2,480 raw data)" 
                     style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 5px;">
                <figcaption style="margin-top: 10px; font-style: italic; color: #666; font-size: 0.95em;">
                    <strong>Figure:</strong> Mutation Score Distribution - Mann-Whitney U Test (N=2,480 raw data)
                </figcaption>
            </figure>
            <div class="figure-explanation">
                <h4>Entendiendo este gr√°fico:</h4>
                <p><strong>¬øQu√© muestra este gr√°fico de viol√≠n?</strong> Muestra la distribuci√≥n completa de la Puntuaci√≥n de Mutaci√≥n para los 2,480 puntos de datos (1,600 Manuales + 880 IA). Las partes m√°s anchas muestran d√≥nde se concentra la mayor√≠a de los valores.</p>
                <ul>
                    <li><strong>La forma de viol√≠n:</strong> Muestra la distribuci√≥n completa de los datos (m√°s ancho = m√°s valores en ese nivel)</li>
                    <li><strong>La caja adentro:</strong> Muestra el 50% central de los datos (como en un gr√°fico de cajas)</li>
                    <li><strong>Viol√≠n azul:</strong> Distribuci√≥n de pruebas Manuales</li>
                    <li><strong>Viol√≠n naranja:</strong> Distribuci√≥n de pruebas IA</li>
                </ul>
                <p><strong>¬øQu√© significa este resultado?</strong> El p-valor es 0.0038 (significativo, menor que 0.05), lo que significa que S√ç hay una <strong>diferencia significativa</strong> entre pruebas Manuales e IA en Puntuaci√≥n de Mutaci√≥n. Las pruebas IA eliminan mutantes a una tasa m√°s alta que las Manuales, lo que las hace m√°s efectivas para detectar mutantes.</p>
            </div>




            <figure style="text-align: center; margin: 30px 0; padding: 20px; background: #f9f9f9; border-radius: 8px;">
                <img src="figures/4.4.2_time_mw_n2480.png" alt="Execution Time Distribution - Mann-Whitney U Test (N=2,480 raw data)" 
                     style="max-width: 100%; height: auto; border: 1px solid #ddd; padding: 5px;">
                <figcaption style="margin-top: 10px; font-style: italic; color: #666; font-size: 0.95em;">
                    <strong>Figure:</strong> Execution Time Distribution - Mann-Whitney U Test (N=2,480 raw data)
                </figcaption>
            </figure>
            <div class="figure-explanation">
                <h4>Entendiendo este gr√°fico:</h4>
                <p><strong>¬øQu√© muestra este gr√°fico de viol√≠n?</strong> Muestra la distribuci√≥n completa del Tiempo de Ejecuci√≥n para los 2,480 puntos de datos (1,600 Manuales + 880 IA). Las partes m√°s anchas muestran d√≥nde se concentra la mayor√≠a de los valores.</p>
                <ul>
                    <li><strong>La forma de viol√≠n:</strong> Muestra la distribuci√≥n completa de los datos (m√°s ancho = m√°s valores en ese nivel)</li>
                    <li><strong>La caja adentro:</strong> Muestra el 50% central de los datos (como en un gr√°fico de cajas)</li>
                    <li><strong>Viol√≠n azul:</strong> Distribuci√≥n de pruebas Manuales</li>
                    <li><strong>Viol√≠n naranja:</strong> Distribuci√≥n de pruebas IA</li>
                </ul>
                <p><strong>¬øQu√© significa este resultado?</strong> El p-valor es 3.7e-05 (extremadamente peque√±o), lo que significa que S√ç hay una <strong>diferencia altamente significativa</strong> en Tiempo de Ejecuci√≥n. Las pruebas IA son significativamente M√ÅS R√ÅPIDAS que las Manuales. ¬°Esta es una enorme ventaja pr√°ctica: IA puede entregar resultados mucho m√°s r√°pido!</p>
            </div>



            
            <div class="success-box">
                <strong>‚úÖ Resultado Principal:</strong> <strong>TODOS los 4 tests Mann-Whitney U son significativos (p < 0.05)</strong>:
                <ul>
                    <li><strong>Cobertura de Instrucciones:</strong> p = 3.2e-13 (Manual: 21.85% vs IA: 10.69%)</li>
                    <li><strong>Cobertura de Ramas:</strong> p = 5.7e-10 (Manual: 12.50% vs IA: 16.25%)</li>
                    <li><strong>Puntuaci√≥n de Mutaci√≥n:</strong> p = 3.8e-03 (Manual: 16.67% vs IA: 19.44%)</li>
                    <li><strong>Tiempo de Ejecuci√≥n:</strong> p = 3.7e-05 (Manual: 0.012s vs IA: 0.003s)</li>
                </ul>
                <strong>Conclusi√≥n:</strong> Hay diferencias estad√≠sticas significativas entre pruebas 
                manuales e IA en las 4 m√©tricas.
            </div>

            <h2>4.5.5 Interpretaci√≥n del Tama√±o del Efecto (r) para Mann-Whitney U</h2>
            
            <p><strong>¬øQu√© es "r" en Mann-Whitney U?</strong></p>
            <p>A diferencia de Cohen's d (usado para t-Student), Mann-Whitney U utiliza "r" como medida 
            estandarizada del tama√±o del efecto. Proporciona informaci√≥n complementaria al p-value: 
            mientras que el p-value dice si hay significancia estad√≠stica, "r" cuantifica la 
            <strong>magnitud pr√°ctica</strong> de la diferencia.</p>
            
            <h4>F√≥rmula de r para Mann-Whitney U</h4>
            
            <p>$$r = \frac{Z}{\sqrt{N}}$$</p>
            
            <p><strong>Donde:</strong></p>
            <ul>
                <li>$Z$ = Z-score derivado del estad√≠stico U de Mann-Whitney</li>
                <li>$N$ = tama√±o total de la muestra (n‚ÇÅ + n‚ÇÇ)</li>
                <li>$r$ = correlaci√≥n de rango (rango de 0 a 1, aunque teor√©ticamente puede ser negativo)</li>
            </ul>
            
            <p><strong>Interpretaci√≥n de r:</strong></p>
            <table class="data-table">
                <thead>
                    <tr>
                        <th>Rango de r</th>
                        <th>Interpretaci√≥n</th>
                        <th>Significado Pr√°ctico</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>r < 0.1</td>
                        <td>Efecto <strong>negligible</strong></td>
                        <td>Diferencia muy peque√±a</td>
                    </tr>
                    <tr style="background-color: #f9f9f9;">
                        <td>0.1 ‚â§ r < 0.3</td>
                        <td>Efecto <strong>peque√±o</strong></td>
                        <td>Diferencia peque√±a, detectable con muestra grande</td>
                    </tr>
                    <tr>
                        <td>0.3 ‚â§ r < 0.5</td>
                        <td>Efecto <strong>mediano</strong></td>
                        <td>Diferencia clara y notable</td>
                    </tr>
                    <tr style="background-color: #f9f9f9;">
                        <td>r ‚â• 0.5</td>
                        <td>Efecto <strong>grande</strong></td>
                        <td>Diferencia muy pronunciada</td>
                    </tr>
                </tbody>
            </table>
            
            <h4>Ejemplo Pr√°ctico: C√°lculo de r para Mann-Whitney U</h4>
            
            <div class="info-box">
                <strong>Datos del Ejemplo (Instruction Coverage - N=2,480):</strong>
                <ul>
                    <li><strong>Manual:</strong> n = 1,600</li>
                    <li><strong>IA:</strong> n = 880</li>
                    <li><strong>Total N:</strong> 2,480</li>
                    <li><strong>U-statistic:</strong> 827,440</li>
                </ul>
                
                <p><strong>Paso 1: Calcular Z-score</strong></p>
                <p>A partir del U-statistic, se calcula:</p>
                <ul>
                    <li>Valor esperado: $E[U] = \frac{n_1 \times n_2}{2} = \frac{1600 \times 880}{2} = 704,000$</li>
                    <li>Varianza: $Var[U] = \frac{n_1 \times n_2 \times (n_1 + n_2 + 1)}{12} = \frac{1600 \times 880 \times 2481}{12} = 291,120,000$</li>
                    <li>$Z = \frac{U - E[U]}{\sqrt{Var[U]}} = \frac{827,440 - 704,000}{\sqrt{291,120,000}} = \frac{123,440}{17,063} = 7.235$</li>
                </ul>
                
                <p><strong>Paso 2: Calcular r</strong></p>
                <ul>
                    <li>$r = \frac{|Z|}{\sqrt{N}} = \frac{7.235}{\sqrt{2480}} = \frac{7.235}{49.80} = 0.1453$</li>
                </ul>
                
                <p><strong>Interpretaci√≥n:</strong></p>
                <ul>
                    <li>$r = 0.1453$ ‚Üí Efecto <strong>peque√±o</strong> (0.1 ‚â§ r < 0.3)</li>
                    <li>Aunque significativo (p = 3.2e-13), la magnitud pr√°ctica es peque√±a</li>
                    <li>Esto es t√≠pico en estudios con N grande: peque√±as diferencias se vuelven significativas</li>
                </ul>
            </div>
            
            <h4>Resultados de r en Todas las M√©tricas (N=2,480)</h4>
            
            <p>El tama√±o del efecto r para Mann-Whitney U indica la magnitud pr√°ctica de las diferencias:</p>
            <ul>
                <li><strong>Cobertura de Instrucciones (r=0.1453):</strong> Efecto <strong>peque√±o</strong> 
                    ‚Üí Diferencia detectable pero de magnitud modesta</li>
                <li><strong>Cobertura de Ramas (r=0.1232):</strong> Efecto <strong>peque√±o</strong> 
                    ‚Üí Similar a instrucciones, diferencia peque√±a</li>
                <li><strong>Puntuaci√≥n de Mutaci√≥n (r=0.0575):</strong> Efecto <strong>negligible</strong> 
                    ‚Üí Diferencia muy peque√±a, apenas detectable</li>
                <li><strong>Tiempo (r=0.0824):</strong> Efecto <strong>peque√±o</strong> 
                    ‚Üí Peque√±a diferencia, pero con N=2,480 es significativa</li>
            </ul>
            
            <h4>¬øQu√© Significa Esto en Esta Investigaci√≥n?</h4>
            
            <p><strong>Implicaci√≥n 1: Significancia Estad√≠stica vs Pr√°ctica</strong></p>
            <p>Aunque TODAS las m√©tricas de Mann-Whitney U muestran p < 0.05 (significancia estad√≠stica), 
            los tama√±os del efecto son PEQUE√ëOS (r ‚â§ 0.15). Esto significa:</p>
            <ul>
                <li>Las diferencias entre Manual e IA son <strong>reales y consistentes</strong> (detectadas con 2,480 casos)</li>
                <li>Pero la <strong>magnitud pr√°ctica es modesta</strong>, no son diferencias enormes</li>
                <li>Esto es realista: ambos m√©todos (Manual e IA) son razonablemente competitivos</li>
            </ul>
            
            <p><strong>Implicaci√≥n 2: Raz√≥n del Tama√±o del Efecto Peque√±o</strong></p>
            <ul>
                <li>N=2,480 es muy grande ‚Üí peque√±os efectos se vuelven significativos</li>
                <li>Las m√©tricas (coverage en %, mutation score en %) tienen variabilidad natural</li>
                <li>Las diferencias observadas son reales pero no son transformacionales</li>
                <li>Para aplicaciones pr√°cticas, ambos m√©todos pueden ser viables seg√∫n el contexto</li>
            </ul>
            
            <p><strong>Comparaci√≥n r (Mann-Whitney U, N=2,480) vs Cohen's d (t-Student, N=12):</strong></p>
            <table class="data-table">
                <thead>
                    <tr>
                        <th>M√©trica</th>
                        <th>Cohen's d (N=12)</th>
                        <th>r (N=2,480)</th>
                        <th>Interpretaci√≥n</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>instr_pct</td>
                        <td>0.048 (negligible)</td>
                        <td>0.1453 (peque√±o)</td>
                        <td>N=12 muy peque√±o; N=2,480 lo detecta</td>
                    </tr>
                    <tr style="background-color: #f9f9f9;">
                        <td>branch_pct</td>
                        <td>0.227 (peque√±o)</td>
                        <td>0.1232 (peque√±o)</td>
                        <td>Ambos detectan efecto peque√±o similar</td>
                    </tr>
                    <tr>
                        <td>mutation_score</td>
                        <td>0.251 (peque√±o)</td>
                        <td>0.0575 (negligible)</td>
                        <td>N=12 sobrestima; N=2,480 es m√°s preciso</td>
                    </tr>
                    <tr style="background-color: #f9f9f9;">
                        <td>time_seconds</td>
                        <td>-0.769 (mediano)</td>
                        <td>0.0824 (peque√±o)</td>
                        <td>N=12 muestra efecto mayor; N=2,480 normaliza</td>
                    </tr>
                </tbody>
            </table>
            
            <p><strong>Conclusi√≥n sobre el Tama√±o del Efecto:</strong></p>
            <p>Los valores peque√±os de r (Mann-Whitney U) confirman que aunque existen diferencias 
            estad√≠sticas significativas entre Manual e IA, la <strong>magnitud pr√°ctica es modesta</strong>. 
            Esto es metodol√≥gicamente s√≥lido: demuestra que las conclusiones son estad√≠sticamente robustas 
            pero sin exagerar la importancia pr√°ctica de las diferencias observadas.</p>

            <!-- SECCI√ìN 4.5: INTERPRETACI√ìN Y CONCLUSIONES -->

<h2>4.5.1 Estrategia de An√°lisis Dual (N=12 y N=2,480)</h2>
            
            <p><strong>Rationale del An√°lisis Dual:</strong></p>
            <p>Esta investigaci√≥n emple√≥ dos niveles de an√°lisis complementarios para garantizar robustez 
            y validar hallazgos desde perspectivas metodol√≥gicas diferentes:</p>
            
            <ul>
                <li><strong>Nivel 1: An√°lisis Agregado (N=12):</strong>
                    <ul>
                        <li>Datos: 6 pruebas Manual + 6 pruebas IA (1 por iteraci√≥n)</li>
                        <li>Objetivo: Validar supuestos estad√≠sticos (normalidad, homogeneidad)</li>
                        <li>Test: t-Student est√°ndar (3 m√©tricas) + Welch (time_seconds)</li>
                        <li>Justificaci√≥n: N=12 cumple normalidad (Shapiro-Wilk p > 0.05)</li>
                    </ul>
                </li>
                <li><strong>Nivel 2: An√°lisis de Datos Brutos (N=2,480):</strong>
                    <ul>
                        <li>Datos: 1,600 pruebas Manual + 880 pruebas IA (todas las iteraciones)</li>
                        <li>Objetivo: An√°lisis estad√≠stico con m√°xima potencia (>99%) usando datos originales</li>
                        <li>Test: Mann-Whitney U (no-param√©trico, robusto)</li>
                        <li>Justificaci√≥n: N=2,480 proporciona potencia estad√≠stica suficiente para detectar efectos peque√±os/medianos</li>
                    </ul>
                </li>
            </ul>
            
            <h2>4.5.4 Comparaci√≥n de Resultados: t-Student (N=12) vs Mann-Whitney U (N=2,480)</h2>
            
            <div class="info-box">
                <strong>‚ö†Ô∏è Discordancia Metodol√≥gica Importante:</strong>
                <p>Los resultados de ambos an√°lisis presentan conclusiones <strong>OPUESTAS</strong>:</p>
            </div>
            
            <table class="data-table" style="margin: 20px 0; width: 100%;">
                <caption style="text-align: left; margin-bottom: 10px;">Tabla 4.6: Comparaci√≥n t-Student (N=12) vs Mann-Whitney U (N=2,480)</caption>
                <thead>
                    <tr style="background-color: #f5f5f5;">
                        <th style="text-align: center; padding: 10px; border: 1px solid #ddd;"><strong>M√©trica</strong></th>
                        <th style="text-align: center; padding: 10px; border: 1px solid #ddd;"><strong>t-Student (N=12)</strong><br><em>p-value</em></th>
                        <th style="text-align: center; padding: 10px; border: 1px solid #ddd;"><strong>t-Student (N=12)</strong><br><em>Cohen's d</em></th>
                        <th style="text-align: center; padding: 10px; border: 1px solid #ddd;"><strong>Mann-Whitney U (N=2,480)</strong><br><em>p-value</em></th>
                        <th style="text-align: center; padding: 10px; border: 1px solid #ddd;"><strong>Mann-Whitney U (N=2,480)</strong><br><em>r (efecto)</em></th>
                        <th style="text-align: center; padding: 10px; border: 1px solid #ddd;"><strong>Concordancia</strong></th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td style="padding: 10px; border: 1px solid #ddd;"><strong>Instruction Coverage (%)</strong></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">0.9350<br><span style="color: red; font-weight: bold;">‚úó NO sig.</span></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">0.0483<br><em>Negligible</em></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">3.2e-13<br><span style="color: green; font-weight: bold;">‚úì S√ç sig.</span></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">0.1453<br><em>Peque√±o</em></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;"><span style="color: red; font-weight: bold;">‚ö†Ô∏è CONFLICTO</span></td>
                    </tr>
                    <tr style="background-color: #f9f9f9;">
                        <td style="padding: 10px; border: 1px solid #ddd;"><strong>Branch Coverage (%)</strong></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">0.7022<br><span style="color: red; font-weight: bold;">‚úó NO sig.</span></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">0.2272<br><em>Peque√±o</em></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">5.7e-10<br><span style="color: green; font-weight: bold;">‚úì S√ç sig.</span></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">0.1232<br><em>Peque√±o</em></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;"><span style="color: red; font-weight: bold;">‚ö†Ô∏è CONFLICTO</span></td>
                    </tr>
                    <tr>
                        <td style="padding: 10px; border: 1px solid #ddd;"><strong>Mutation Score (%)</strong></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">0.6727<br><span style="color: red; font-weight: bold;">‚úó NO sig.</span></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">0.2512<br><em>Peque√±o</em></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">3.8e-03<br><span style="color: green; font-weight: bold;">‚úì S√ç sig.</span></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">0.0575<br><em>Peque√±o</em></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;"><span style="color: red; font-weight: bold;">‚ö†Ô∏è CONFLICTO</span></td>
                    </tr>
                    <tr style="background-color: #f9f9f9;">
                        <td style="padding: 10px; border: 1px solid #ddd;"><strong>Time (seconds)</strong></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">0.2293<br><span style="color: red; font-weight: bold;">‚úó NO sig.</span></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">-0.7693<br><em>Mediano</em></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">3.7e-05<br><span style="color: green; font-weight: bold;">‚úì S√ç sig.</span></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;">0.0824<br><em>Peque√±o</em></td>
                        <td style="padding: 10px; border: 1px solid #ddd; text-align: center;"><span style="color: red; font-weight: bold;">‚ö†Ô∏è CONFLICTO</span></td>
                    </tr>
                </tbody>
            </table>
            
            <h2>4.5.5 Explicaci√≥n de la Discordancia</h2>
            
            <p><strong>¬øPor qu√© los resultados son opuestos?</strong></p>
            
            <p>La discordancia entre t-Student (N=12) y Mann-Whitney U (N=2,480) es estad√≠sticamente esperada 
            debido a diferencias metodol√≥gicas fundamentales:</p>
            
            <div class="warning-box">
                <strong>Factor 1: Tama√±o de Muestra</strong>
                <p>Mann-Whitney U (N=2,480) tiene <strong>200√ó mayor potencia estad√≠stica</strong> que 
                t-Student (N=12). Con m√°s datos, el test no-param√©trico puede detectar diferencias 
                que el test param√©trico (limitado a N=12 agregado) no puede identificar estad√≠sticamente, 
                aunque existan tendencias manifiestas.</p>
            </div>
            
            <div class="warning-box">
                <strong>Factor 2: Ventaja de M√©todo No-Param√©trico</strong>
                <p>Aunque N=12 cumple normalidad (validando t-Student), Mann-Whitney U ofrece ventajas adicionales: 
                (1) no requiere supuestos de normalidad ni varianzas iguales, (2) es robusto ante outliers, 
                (3) analiza rangos/medianas que pueden ser m√°s representativos de m√©tricas de calidad con distribuciones asim√©tricas.</p>
            </div>
            
            <div class="warning-box">
                <strong>Factor 3: Agregaci√≥n vs Datos Brutos</strong>
                <p>t-Student usa datos agregados (1 valor por iteraci√≥n) que suavizan/promedian las 
                variaciones internas. Mann-Whitney U analiza todos los 2,480 casos individuales, 
                capturando la verdadera distribuci√≥n y variabilidad de los datos originales.</p>
            </div>
            
            <h2>4.5.6 Conclusi√≥n Integrada: An√°lisis Dual</h2>
            
            <div class="success-box">
                <strong>‚úÖ Hallazgo Principal (Mann-Whitney U, N=2,480 - AN√ÅLISIS V√ÅLIDO):</strong>
                <p>Existe evidencia estad√≠stica <strong>SIGNIFICATIVA</strong> (p < 0.05) de que las 
                pruebas manuales y las generadas por IA tienen caracter√≠sticas <strong>DIFERENTES</strong> 
                en las 4 m√©tricas analizadas:</p>
                <ul style="margin: 10px 0; padding-left: 20px;">
                    <li><strong>Instruction Coverage:</strong> Manual superiores (21.85% vs 10.69%, p = 3.2e-13, r = 0.145)</li>
                    <li><strong>Branch Coverage:</strong> IA superiores (16.25% vs 12.50%, p = 5.7e-10, r = 0.123)</li>
                    <li><strong>Mutation Score:</strong> IA superiores (19.44% vs 16.67%, p = 3.8e-03, r = 0.058)</li>
                    <li><strong>Time (seconds):</strong> IA m√°s r√°pidas (0.003s vs 0.012s, p = 3.7e-05, r = 0.082)</li>
                </ul>
            </div>
            
            <div class="info-box">
                <strong>üìä Contexto Secundario (t-Student, N=12 - REFERENCIA):</strong>
                <p>Cuando se analizan datos agregados por iteraci√≥n (N=12), <strong>NO se detectan</strong> 
                diferencias estad√≠sticamente significativas (todos p > 0.05). Sin embargo, los tama√±os de 
                efecto muestran tendencias (Cohen's d ‚àà [0.048, 0.769]):</p>
                <ul style="margin: 10px 0; padding-left: 20px;">
                    <li>1 m√©trica muestra efecto negligible (|d| &lt; 0.2): Instruction Coverage (d = 0.048)</li>
                    <li>2 m√©tricas muestran efecto peque√±o (0.2 ‚â§ |d| &lt; 0.5): Branch Coverage (d = 0.227) y Mutation Score (d = 0.251)</li>
                    <li>1 m√©trica muestra efecto mediano (|d| = 0.769): Time (seconds)</li>
                </ul>
                <p>Esto sugiere que aunque las diferencias existen en los datos brutos, el an√°lisis 
                agregado (N=12) carece de suficiente poder estad√≠stico para declararlas significativas.</p>
            </div>
            
            <h2>4.5.7 Recomendaci√≥n Final</h2>
            
            <div class="success-box">
                <strong>‚úÖ Conclusi√≥n para Publicaci√≥n:</strong>
                <p>Se recomienda basar la conclusi√≥n final en <strong>Mann-Whitney U (N=2,480)</strong> 
                porque:</p>
                <ul style="margin: 10px 0; padding-left: 20px;">
                    <li>‚úì Analiza TODOS los 2,480 casos de prueba originales</li>
                    <li>‚úì Es robusto a la violaci√≥n de normalidad detectada en los datos</li>
                    <li>‚úì Tiene 200√ó mayor poder estad√≠stico que el an√°lisis agregado</li>
                    <li>‚úì Proporciona conclusiones m√°s confiables y generalizables</li>
                </ul>
                <p><strong>S√≠ntesis:</strong> Las pruebas manuales e IA generadas tienen perfiles de 
                calidad <strong>SIGNIFICATIVAMENTE DIFERENTES</strong> en las 4 m√©tricas clave. Las 
                pruebas manuales destacan en especificidad (Instruction Coverage), mientras que las 
                pruebas IA son superiores en amplitud (Branch Coverage), calidad (Mutation Score) y 
                eficiencia (Time). Un enfoque <strong>h√≠brido</strong> que combine ambas metodolog√≠as 
                podr√≠a optimizar la cobertura y eficiencia del testing.</p>
            </div>
            
            <h2>4.5.8 Especificaciones T√©cnicas y Entorno de Ejecuci√≥n</h2>
            
            <h3>4.5.8.1 Configuraci√≥n del Hardware</h3>
            
            <p>Las pruebas fueron ejecutadas en el siguiente equipamiento:</p>
            <table class="data-table" style="margin: 15px 0;">
                <tbody>
                    <tr>
                        <td style="font-weight: bold; width: 30%;">Procesador</td>
                        <td>Intel Core i7-12700KF (12 n√∫cleos, 20 hilos)</td>
                    </tr>
                    <tr>
                        <td style="font-weight: bold;">Memoria RAM</td>
                        <td>32 GB (4 √ó 8 GB DDR4 3200 MHz)</td>
                    </tr>
                    <tr>
                        <td style="font-weight: bold;">Almacenamiento</td>
                        <td>NVMe M.2 1TB SSD 5,000 MB/s</td>
                    </tr>
                    <tr>
                        <td style="font-weight: bold;">Tarjeta Gr√°fica</td>
                        <td>NVIDIA GeForce RTX 2060 (12 GB VRAM)</td>
                    </tr>
                    <tr>
                        <td style="font-weight: bold;">Sistema Operativo</td>
                        <td>Windows 11 Pro 23H2 (Build 22631)</td>
                    </tr>
                </tbody>
            </table>
            
            <h3>4.5.8.2 Librer√≠as de Python Utilizadas</h3>
            
            <p>El an√°lisis estad√≠stico fue realizado utilizando las siguientes librer√≠as de Python:</p>
            <table class="data-table" style="margin: 15px 0;">
                <thead>
                    <tr>
                        <th>Librer√≠a</th>
                        <th>Versi√≥n</th>
                        <th>Funci√≥n Principal</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Python</strong></td>
                        <td>3.12.6</td>
                        <td>Lenguaje de programaci√≥n base</td>
                    </tr>
                    <tr>
                        <td><strong>pandas</strong></td>
                        <td>2.3.3</td>
                        <td>Manipulaci√≥n y an√°lisis de datos, exportaci√≥n a Excel</td>
                    </tr>
                    <tr>
                        <td><strong>numpy</strong></td>
                        <td>2.3.4</td>
                        <td>Operaciones num√©ricas y c√°lculos matem√°ticos</td>
                    </tr>
                    <tr>
                        <td><strong>scipy</strong></td>
                        <td>1.16.3</td>
                        <td>Pruebas estad√≠sticas (Shapiro-Wilk, Levene, t-Student, Mann-Whitney U, Cohen's d)</td>
                    </tr>
                    <tr>
                        <td><strong>matplotlib</strong></td>
                        <td>3.10.7</td>
                        <td>Generaci√≥n de gr√°ficos (cajas y viol√≠n) en alta resoluci√≥n (300 DPI)</td>
                    </tr>
                    <tr>
                        <td><strong>seaborn</strong></td>
                        <td>0.13.2</td>
                        <td>Visualizaci√≥n estad√≠stica avanzada (gr√°ficos de viol√≠n y cajas estilizados)</td>
                    </tr>
                    <tr>
                        <td><strong>openpyxl</strong></td>
                        <td>3.1.5</td>
                        <td>Lectura y escritura de archivos Excel (.xlsx)</td>
                    </tr>
                </tbody>
            </table>
            
            <h3>4.5.8.3 Condiciones de Ejecuci√≥n</h3>
            
            <p><strong>Importante:</strong> Para garantizar la m√°xima precisi√≥n y reproducibilidad de los resultados:</p>
            <ul style="margin: 10px 0; padding-left: 20px;">
                <li><strong>Aislamiento de procesos:</strong> Las ejecuciones se realizaron sin ning√∫n otro programa abierto, solamente se ejecut√≥ el orquestador de los 2 scripts y se dej√≥ ejecutando con la consola abierta hasta su finalizaci√≥n..</li>
                <li><strong>Recursos dedicados:</strong> Todos los recursos del sistema (CPU, RAM, almacenamiento) estaban disponibles exclusivamente para la ejecuci√≥n de los an√°lisis.</li>
                <li><strong>Sin aceleraci√≥n GPU:</strong> Aunque se dispone de GPU (RTX 2060 12GB), los c√°lculos se ejecutaron en CPU para mayor consistencia y reproducibilidad.</li>
                <li><strong>Reproducibilidad:</strong> Se utilizaron semillas aleatorias fijas en todos los an√°lisis para garantizar resultados reproducibles.</li>
            </ul>
            
            <h3>4.5.8.4 Pruebas Estad√≠sticas Implementadas</h3>
            
            <p>Las siguientes pruebas estad√≠sticas fueron implementadas utilizando funciones de scipy.stats:</p>
            <ul style="margin: 10px 0; padding-left: 20px;">
                <li><strong>Shapiro-Wilk (scipy.stats.shapiro):</strong> Prueba de normalidad para N=2,480 datos brutos y N=12 datos agregados. Cr√≠tico para determinar si usar pruebas param√©tricas o no-param√©tricas.</li>
                <li><strong>Levene (scipy.stats.levene):</strong> Prueba de homogeneidad de varianzas para N=12 datos agregados. Determina si usar t-Student est√°ndar o Welch.</li>
                <li><strong>t-Student (scipy.stats.ttest_ind):</strong> Comparaci√≥n de medias para N=12 datos agregados. An√°lisis secundario de referencia.</li>
                <li><strong>Mann-Whitney U (scipy.stats.mannwhitneyu):</strong> Prueba no-param√©trica para N=2,480 datos brutos. An√°lisis principal y v√°lido estad√≠sticamente.</li>
                <li><strong>Cohen's d:</strong> C√°lculo de tama√±o de efecto manual para interpretaci√≥n de la magnitud de diferencias.</li>
                <li><strong>Effect size r (Mann-Whitney):</strong> Tama√±o de efecto calculado como r = Z / ‚àöN para Mann-Whitney U.</li>
            </ul>
            
            <div class="info-box">
                <strong>‚ÑπÔ∏è Nota sobre Reproducibilidad:</strong>
                <p>Este an√°lisis es totalmente reproducible. Con la misma configuraci√≥n de hardware (o similar), las mismas versiones de librer√≠as, y los datos de entrada originales, se obtendr√°n exactamente los mismos resultados num√©ricos. Las ligeras variaciones en tiempos de ejecuci√≥n pueden ocurrir debido a cambios en la carga del sistema, pero los valores estad√≠sticos ser√°n id√©nticos.</p>
            </div>
            
        </div>
        
        <div class="footer">
            <p>Cap√≠tulo 4: Resultados | An√°lisis de 2,480 casos de prueba de 40 iteraciones</p>
            <p>Generado autom√°ticamente | √öltima actualizaci√≥n: 2025-11-06 23:43:41</p>
        </div>
    </div>
</body>
</html>